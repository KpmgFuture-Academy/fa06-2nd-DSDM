{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b659824f",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740cd8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\ML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import optuna\n",
    "import os\n",
    "import json\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b52e81",
   "metadata": {},
   "source": [
    "# Data Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d0935bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ./train/íšŒì›ì •ë³´/201807_train_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/íšŒì›ì •ë³´/201808_train_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/íšŒì›ì •ë³´/201809_train_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/íšŒì›ì •ë³´/201810_train_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/íšŒì›ì •ë³´/201811_train_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/íšŒì›ì •ë³´/201812_train_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/íšŒì›ì •ë³´/train_íšŒì›ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 78))\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/201807_train_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/201808_train_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/201809_train_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/201810_train_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/201811_train_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/201812_train_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì‹ ìš©ì •ë³´/train_ì‹ ìš©ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 42))\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201807_train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201808_train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201809_train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201810_train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201811_train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201812_train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ìŠ¹ì¸ë§¤ì¶œì •ë³´/train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 406))\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/201807_train_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/201808_train_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/201809_train_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/201810_train_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/201811_train_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/201812_train_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì²­êµ¬ì…ê¸ˆì •ë³´/train_ì²­êµ¬ì…ê¸ˆì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 46))\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/201807_train_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/201808_train_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/201809_train_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/201810_train_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/201811_train_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/201812_train_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì”ì•¡ì •ë³´/train_ì”ì•¡ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 82))\n",
      "âœ… ./train/ì±„ë„ì •ë³´/201807_train_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì±„ë„ì •ë³´/201808_train_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì±„ë„ì •ë³´/201809_train_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì±„ë„ì •ë³´/201810_train_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì±„ë„ì •ë³´/201811_train_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì±„ë„ì •ë³´/201812_train_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì±„ë„ì •ë³´/train_ì±„ë„ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 105))\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/201807_train_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/201808_train_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/201809_train_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/201810_train_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/201811_train_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/201812_train_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ë§ˆì¼€íŒ…ì •ë³´/train_ë§ˆì¼€íŒ…ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 64))\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/201807_train_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/201808_train_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/201809_train_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/201810_train_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/201811_train_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/201812_train_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./train/ì„±ê³¼ì •ë³´/train_ì„±ê³¼ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (2400000, 49))\n",
      "âœ… ./test/íšŒì›ì •ë³´/201807_test_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/íšŒì›ì •ë³´/201808_test_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/íšŒì›ì •ë³´/201809_test_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/íšŒì›ì •ë³´/201810_test_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/íšŒì›ì •ë³´/201811_test_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/íšŒì›ì •ë³´/201812_test_íšŒì›ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/íšŒì›ì •ë³´/test_íšŒì›ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 77))\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/201807_test_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/201808_test_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/201809_test_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/201810_test_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/201811_test_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/201812_test_ì‹ ìš©ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì‹ ìš©ì •ë³´/test_ì‹ ìš©ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 42))\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201807_test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201808_test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201809_test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201810_test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201811_test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/201812_test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ìŠ¹ì¸ë§¤ì¶œì •ë³´/test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 406))\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/201807_test_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/201808_test_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/201809_test_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/201810_test_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/201811_test_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/201812_test_ì²­êµ¬ì…ê¸ˆì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì²­êµ¬ì…ê¸ˆì •ë³´/test_ì²­êµ¬ì…ê¸ˆì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 46))\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/201807_test_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/201808_test_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/201809_test_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/201810_test_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/201811_test_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/201812_test_ì”ì•¡ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì”ì•¡ì •ë³´/test_ì”ì•¡ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 82))\n",
      "âœ… ./test/ì±„ë„ì •ë³´/201807_test_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì±„ë„ì •ë³´/201808_test_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì±„ë„ì •ë³´/201809_test_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì±„ë„ì •ë³´/201810_test_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì±„ë„ì •ë³´/201811_test_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì±„ë„ì •ë³´/201812_test_ì±„ë„ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì±„ë„ì •ë³´/test_ì±„ë„ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 105))\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/201807_test_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/201808_test_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/201809_test_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/201810_test_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/201811_test_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/201812_test_ë§ˆì¼€íŒ…ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ë§ˆì¼€íŒ…ì •ë³´/test_ë§ˆì¼€íŒ…ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 64))\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/201807_test_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/201808_test_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/201809_test_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/201810_test_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/201811_test_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/201812_test_ì„±ê³¼ì •ë³´.parquet ë³€í™˜ ì™„ë£Œ\n",
      "âœ… ./test/ì„±ê³¼ì •ë³´/test_ì„±ê³¼ì •ë³´.csv ì €ì¥ ì™„ë£Œ (Shape: (600000, 49))\n"
     ]
    }
   ],
   "source": [
    "months = [\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "categories = [\"íšŒì›ì •ë³´\", \"ì‹ ìš©ì •ë³´\", \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\", \"ì²­êµ¬ì…ê¸ˆì •ë³´\", \"ì”ì•¡ì •ë³´\", \"ì±„ë„ì •ë³´\", \"ë§ˆì¼€íŒ…ì •ë³´\", \"ì„±ê³¼ì •ë³´\"]\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "def merge_monthly_data(data_type, category):\n",
    "    merged_list = []\n",
    "    for month in months:\n",
    "        file_name = f\"./{data_type}/{category}/2018{month}_{data_type}_{category}.parquet\"\n",
    "        try:\n",
    "            df = pd.read_parquet(file_name, engine=\"pyarrow\")\n",
    "            merged_list.append(df)\n",
    "            print(f\"âœ… {file_name} ë³€í™˜ ì™„ë£Œ\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âš ï¸ íŒŒì¼ ì—†ìŒ: {file_name}\")\n",
    "    if merged_list:\n",
    "        merged_df = pd.concat(merged_list, ignore_index=True)\n",
    "        output_file = f\"./{data_type}/{category}/{data_type}_{category}.csv\"\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"âœ… {output_file} ì €ì¥ ì™„ë£Œ (Shape: {merged_df.shape})\")\n",
    "    else:\n",
    "        print(f\"âŒ {data_type}_{category} ë°ì´í„° ì—†ìŒ\")\n",
    "\n",
    "for data_type in data_types:\n",
    "    for category in categories:\n",
    "        merge_monthly_data(data_type, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f515f",
   "metadata": {},
   "source": [
    "# Data Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c1b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ì‹ ìš©ì •ë³´.csv (2/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 118)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv (3/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\1239001571.py:15: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 522)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ì²­êµ¬ì…ê¸ˆì •ë³´.csv (4/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 566)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ì”ì•¡ì •ë³´.csv (5/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 646)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ì±„ë„ì •ë³´.csv (6/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 749)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ë§ˆì¼€íŒ…ì •ë³´.csv (7/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 811)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: train_ì„±ê³¼ì •ë³´.csv (8/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (2400000, 858)\n",
      "\n",
      "âœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: ./train/base_train.csv\n",
      "ğŸ§¾ ìµœì¢… ë°ì´í„° í¬ê¸°: 2400000í–‰, 858ì—´\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"train_íšŒì›ì •ë³´.csv\",\n",
    "    \"train_ì‹ ìš©ì •ë³´.csv\",\n",
    "    \"train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv\",\n",
    "    \"train_ì²­êµ¬ì…ê¸ˆì •ë³´.csv\",\n",
    "    \"train_ì”ì•¡ì •ë³´.csv\",\n",
    "    \"train_ì±„ë„ì •ë³´.csv\",\n",
    "    \"train_ë§ˆì¼€íŒ…ì •ë³´.csv\",\n",
    "    \"train_ì„±ê³¼ì •ë³´.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f\"./train/{categories[0]}/{file_names[0]}\")\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\nğŸ”¹ ë³‘í•© ì¤‘: {file} ({idx}/{len(file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"ê¸°ì¤€ë…„ì›”\"])\n",
    "    print(f\"âœ… ë³‘í•© í›„ í¬ê¸°: {df.shape}\")\n",
    "\n",
    "output_file = \"./train/base_train.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "print(f\"ğŸ§¾ ìµœì¢… ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰, {df.shape[1]}ì—´\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f51dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ì‹ ìš©ì •ë³´.csv (2/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 117)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv (3/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\879322153.py:15: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 521)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ì²­êµ¬ì…ê¸ˆì •ë³´.csv (4/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 565)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ì”ì•¡ì •ë³´.csv (5/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 645)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ì±„ë„ì •ë³´.csv (6/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 748)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ë§ˆì¼€íŒ…ì •ë³´.csv (7/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 810)\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì¤‘: test_ì„±ê³¼ì •ë³´.csv (8/8)\n",
      "âœ… ë³‘í•© í›„ í¬ê¸°: (600000, 857)\n",
      "\n",
      "âœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: ./test/base_test.csv\n",
      "ğŸ§¾ ìµœì¢… ë°ì´í„° í¬ê¸°: 600000í–‰, 857ì—´\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"test_íšŒì›ì •ë³´.csv\",\n",
    "    \"test_ì‹ ìš©ì •ë³´.csv\",\n",
    "    \"test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv\",\n",
    "    \"test_ì²­êµ¬ì…ê¸ˆì •ë³´.csv\",\n",
    "    \"test_ì”ì•¡ì •ë³´.csv\",\n",
    "    \"test_ì±„ë„ì •ë³´.csv\",\n",
    "    \"test_ë§ˆì¼€íŒ…ì •ë³´.csv\",\n",
    "    \"test_ì„±ê³¼ì •ë³´.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f\"./test/{categories[0]}/{file_names[0]}\")\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\nğŸ”¹ ë³‘í•© ì¤‘: {file} ({idx}/{len(file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"ê¸°ì¤€ë…„ì›”\"])\n",
    "    print(f\"âœ… ë³‘í•© í›„ í¬ê¸°: {df.shape}\")\n",
    "\n",
    "output_file = \"./test/base_test.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}\")\n",
    "print(f\"ğŸ§¾ ìµœì¢… ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰, {df.shape[1]}ì—´\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f695a",
   "metadata": {},
   "source": [
    "# Data Preprocessing - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8413743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ì‹ ìš©ì •ë³´.csv (íŒŒì¼ 2 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 118ì—´\n",
      "ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: ['ì´ìš©ì¹´ë“œìˆ˜_ì²´í¬_ê°€ì¡±', 'ì´ìš©ê¸ˆì•¡_R3M_ì²´í¬_ê°€ì¡±', 'ì—°íšŒë¹„í• ì¸ì¹´ë“œìˆ˜_B0M', 'í• ì¸ê¸ˆì•¡_ê¸°ë³¸ì—°íšŒë¹„_B0M', 'í• ì¸ê¸ˆì•¡_ì œíœ´ì—°íšŒë¹„_B0M', 'ìƒí’ˆê´€ë ¨ë©´ì œì¹´ë“œìˆ˜_B0M', 'ì„ì§ì›ë©´ì œì¹´ë“œìˆ˜_B0M', 'ìš°ìˆ˜íšŒì›ë©´ì œì¹´ë“œìˆ˜_B0M', 'ê¸°íƒ€ë©´ì œì¹´ë“œìˆ˜_B0M', 'ì‹œì¥ì—°ì²´ìƒí™˜ì—¬ë¶€_R3M']\n",
      "ğŸ“Œ ì œê±°ëœ ì¤‘ë³µ ì¹¼ëŸ¼: ['ì²­êµ¬ê¸ˆì•¡_ê¸°ë³¸ì—°íšŒë¹„_B0M', 'ì²­êµ¬ê¸ˆì•¡_ì œíœ´ì—°íšŒë¹„_B0M']\n",
      "ğŸ”¹ train_ì‹ ìš©ì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 106ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv (íŒŒì¼ 3 / 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\4271029770.py:17: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 510ì—´\n",
      "ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: ['ì´ìš©ê±´ìˆ˜_ë¶€ë¶„ë¬´ì´ì_B0M', 'ì´ìš©ê¸ˆì•¡_ë¶€ë¶„ë¬´ì´ì_B0M', 'ì—¬ìœ _ì—¬í–‰ì´ìš©ê¸ˆì•¡', 'ë‚©ë¶€_ë Œíƒˆë£Œì´ìš©ê¸ˆì•¡', 'ë‚©ë¶€_ìœ ì„ ë°©ì†¡ì´ìš©ê¸ˆì•¡', 'ë‚©ë¶€_ê±´ê°•ì—°ê¸ˆì´ìš©ê¸ˆì•¡', 'í• ë¶€ê±´ìˆ˜_ë¶€ë¶„_3M_R12M', 'í• ë¶€ê±´ìˆ˜_ë¶€ë¶„_6M_R12M', 'í• ë¶€ê±´ìˆ˜_ë¶€ë¶„_14M_R12M', 'í• ë¶€ê¸ˆì•¡_ë¶€ë¶„_3M_R12M', 'RPê±´ìˆ˜_ìœ ì„ ë°©ì†¡_B0M', 'RPê±´ìˆ˜_ê±´ê°•_B0M', 'RPí›„ê²½ê³¼ì›”_ìœ ì„ ë°©ì†¡', 'RPí›„ê²½ê³¼ì›”_ê±´ê°•', 'ì¦ê°_RPê±´ìˆ˜_ìœ ì„ ë°©ì†¡_ì „ì›”', 'ì¦ê°_RPê±´ìˆ˜_ê±´ê°•_ì „ì›”', 'ì´ìš©ê°œì›”ìˆ˜_ë‹¹ì‚¬í˜ì´_R6M', 'ì´ìš©ê¸ˆì•¡_ë‹¹ì‚¬í˜ì´_R6M', 'ì´ìš©ê¸ˆì•¡_ë‹¹ì‚¬ê¸°íƒ€_R6M', 'ì´ìš©ê±´ìˆ˜_ë‹¹ì‚¬í˜ì´_R6M', 'ì´ìš©ê±´ìˆ˜_ë‹¹ì‚¬ê¸°íƒ€_R6M', 'ì´ìš©ê¸ˆì•¡_ë‹¹ì‚¬í˜ì´_R3M', 'ì´ìš©ê¸ˆì•¡_ë‹¹ì‚¬ê¸°íƒ€_R3M', 'ì´ìš©ê±´ìˆ˜_ë‹¹ì‚¬í˜ì´_R3M', 'ì´ìš©ê±´ìˆ˜_ë‹¹ì‚¬ê¸°íƒ€_R3M', 'ì´ìš©ê¸ˆì•¡_ë‹¹ì‚¬í˜ì´_B0M', 'ì´ìš©ê¸ˆì•¡_ë‹¹ì‚¬ê¸°íƒ€_B0M', 'ì´ìš©ê±´ìˆ˜_ë‹¹ì‚¬í˜ì´_B0M', 'ì´ìš©ê±´ìˆ˜_ë‹¹ì‚¬ê¸°íƒ€_B0M', 'ìŠ¹ì¸ê±°ì ˆê±´ìˆ˜_ì…ë ¥ì˜¤ë¥˜_B0M', 'ìŠ¹ì¸ê±°ì ˆê±´ìˆ˜_ê¸°íƒ€_B0M']\n",
      "ğŸ“Œ ì œê±°ëœ ì¤‘ë³µ ì¹¼ëŸ¼: ['ì´ìš©íšŸìˆ˜_ì—°ì²´_B0M', 'í• ë¶€ê±´ìˆ˜_ë¶€ë¶„_12M_R12M']\n",
      "ğŸ”¹ train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 477ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ì²­êµ¬ì…ê¸ˆì •ë³´.csv (íŒŒì¼ 4 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 521ì—´\n",
      "ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: ['ëŒ€í‘œê²°ì œë°©ë²•ì½”ë“œ']\n",
      "ğŸ“Œ ì¤‘ë³µ ì¹¼ëŸ¼ ì—†ìŒ\n",
      "ğŸ”¹ train_ì²­êµ¬ì…ê¸ˆì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 520ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ì”ì•¡ì •ë³´.csv (íŒŒì¼ 5 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 600ì—´\n",
      "ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: ['ì¹´ë“œë¡ ì”ì•¡_ìµœì¢…ê²½ê³¼ì›”', 'ìµœì¢…ì—°ì²´ê°œì›”ìˆ˜_R15M', 'RVì”ì•¡ì´ì›”íšŸìˆ˜_R6M', 'RVì”ì•¡ì´ì›”íšŸìˆ˜_R3M', 'ì—°ì²´ì”ì•¡_ì¼ì‹œë¶ˆ_í•´ì™¸_B0M', 'ì—°ì²´ì”ì•¡_RVì¼ì‹œë¶ˆ_í•´ì™¸_B0M', 'ì—°ì²´ì”ì•¡_í• ë¶€_í•´ì™¸_B0M', 'ì—°ì²´ì”ì•¡_CA_í•´ì™¸_B0M']\n",
      "ğŸ“Œ ì¤‘ë³µ ì¹¼ëŸ¼ ì—†ìŒ\n",
      "ğŸ”¹ train_ì”ì•¡ì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 592ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ì±„ë„ì •ë³´.csv (íŒŒì¼ 6 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 695ì—´\n",
      "ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: ['ì¸ì…íšŸìˆ˜_ê¸ˆìœµ_IB_R6M', 'ì¸ì…ë¶ˆë§ŒíšŸìˆ˜_IB_R6M', 'ì¸ì…ë¶ˆë§Œì¼ìˆ˜_IB_R6M', 'ì¸ì…ë¶ˆë§Œì›”ìˆ˜_IB_R6M', 'ì¸ì…ë¶ˆë§Œí›„ê²½ê³¼ì›”_IB_R6M', 'ì¸ì…ë¶ˆë§ŒíšŸìˆ˜_IB_B0M', 'ì¸ì…ë¶ˆë§Œì¼ìˆ˜_IB_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_í•œë„_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ê²°ì œ_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_í• ë¶€_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ì •ë³´ë³€ê²½_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ê²°ì œì¼ë³€ê²½_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ëª…ì„¸ì„œ_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ë¹„ë°€ë²ˆí˜¸_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_SMS_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_APP_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ë¶€ëŒ€ì„œë¹„ìŠ¤_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_í¬ì¸íŠ¸_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_BL_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ë¶„ì‹¤ë„ë‚œ_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_CA_B0M', 'IBìƒë‹´ê±´ìˆ˜_VOC_B0M', 'IBìƒë‹´ê±´ìˆ˜_VOCë¯¼ì›_B0M', 'IBìƒë‹´ê±´ìˆ˜_VOCë¶ˆë§Œ_B0M', 'IBìƒë‹´ê±´ìˆ˜_ê¸ˆê°ì›_B0M', 'IBë¬¸ì˜ê±´ìˆ˜_ëª…ì„¸ì„œ_R6M', 'IBë¬¸ì˜ê±´ìˆ˜_APP_R6M', 'IBìƒë‹´ê±´ìˆ˜_VOC_R6M', 'IBìƒë‹´ê±´ìˆ˜_VOCë¯¼ì›_R6M', 'IBìƒë‹´ê±´ìˆ˜_VOCë¶ˆë§Œ_R6M', 'IBìƒë‹´ê±´ìˆ˜_ê¸ˆê°ì›_R6M', 'ë¶ˆë§Œì œê¸°ê±´ìˆ˜_B0M', 'ë¶ˆë§Œì œê¸°ê±´ìˆ˜_R12M', 'ë‹¹ì‚¬PAY_ë°©ë¬¸íšŸìˆ˜_B0M', 'ë‹¹ì‚¬PAY_ë°©ë¬¸íšŸìˆ˜_R6M', 'ë‹¹ì‚¬PAY_ë°©ë¬¸ì›”ìˆ˜_R6M']\n",
      "ğŸ“Œ ì¤‘ë³µ ì¹¼ëŸ¼ ì—†ìŒ\n",
      "ğŸ”¹ train_ì±„ë„ì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 659ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ë§ˆì¼€íŒ…ì •ë³´.csv (íŒŒì¼ 7 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 721ì—´\n",
      "ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: ['ì»¨íƒê±´ìˆ˜_CA_TM_B0M', 'ì»¨íƒê±´ìˆ˜_í¬ì¸íŠ¸ì†Œì§„_TM_B0M', 'ì»¨íƒê±´ìˆ˜_CA_EM_B0M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_EM_B0M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_ì²­êµ¬ì„œ_B0M', 'ì»¨íƒê±´ìˆ˜_ì¹´ë“œë¡ _ì¸í„°ë„·_B0M', 'ì»¨íƒê±´ìˆ˜_CA_ì¸í„°ë„·_B0M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_ì¸í„°ë„·_B0M', 'ì»¨íƒê±´ìˆ˜_ì¹´ë“œë¡ _ë‹¹ì‚¬ì•±_B0M', 'ì»¨íƒê±´ìˆ˜_CA_ë‹¹ì‚¬ì•±_B0M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_ë‹¹ì‚¬ì•±_B0M', 'ì»¨íƒê±´ìˆ˜_CA_EM_R6M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_EM_R6M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_ì²­êµ¬ì„œ_R6M', 'ì»¨íƒê±´ìˆ˜_ì¹´ë“œë¡ _ì¸í„°ë„·_R6M', 'ì»¨íƒê±´ìˆ˜_CA_ì¸í„°ë„·_R6M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_ì¸í„°ë„·_R6M', 'ì»¨íƒê±´ìˆ˜_ì¹´ë“œë¡ _ë‹¹ì‚¬ì•±_R6M', 'ì»¨íƒê±´ìˆ˜_CA_ë‹¹ì‚¬ì•±_R6M', 'ì»¨íƒê±´ìˆ˜_ë¦¬ë³¼ë¹™_ë‹¹ì‚¬ì•±_R6M', 'ì»¨íƒê±´ìˆ˜_FDS_B0M', 'ì»¨íƒê±´ìˆ˜_FDS_R6M']\n",
      "ğŸ“Œ ì¤‘ë³µ ì¹¼ëŸ¼ ì—†ìŒ\n",
      "ğŸ”¹ train_ë§ˆì¼€íŒ…ì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 699ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: train_ì„±ê³¼ì •ë³´.csv (íŒŒì¼ 8 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 2400000í–‰, 746ì—´\n",
      "ğŸ“Œ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼ ì—†ìŒ\n",
      "ğŸ“Œ ì¤‘ë³µ ì¹¼ëŸ¼ ì—†ìŒ\n",
      "ğŸ”¹ train_ì„±ê³¼ì •ë³´.csv ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: 2400000í–‰, 746ì—´\n",
      "\n",
      "âœ… ì›ë˜ ë°ì´í„° í¬ê¸°: 2400000í–‰, 78ì—´\n",
      "âœ… ë³‘í•© í›„ ìµœì¢… ë°ì´í„° í¬ê¸°: 2400000í–‰, 746ì—´\n",
      "\n",
      "âœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: ./train/base_clean_train.csv\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"train_íšŒì›ì •ë³´.csv\",\n",
    "    \"train_ì‹ ìš©ì •ë³´.csv\",\n",
    "    \"train_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv\",\n",
    "    \"train_ì²­êµ¬ì…ê¸ˆì •ë³´.csv\",\n",
    "    \"train_ì”ì•¡ì •ë³´.csv\",\n",
    "    \"train_ì±„ë„ì •ë³´.csv\",\n",
    "    \"train_ë§ˆì¼€íŒ…ì •ë³´.csv\",\n",
    "    \"train_ì„±ê³¼ì •ë³´.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f\"./train/{categories[0]}/{file_names[0]}\")\n",
    "original_shape = df.shape\n",
    "\n",
    "for idx, file in enumerate(file_names[1:], start=2):    \n",
    "    print(f\"\\nğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: {file} (íŒŒì¼ {idx} / {len(file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"ê¸°ì¤€ë…„ì›”\"])\n",
    "    print(f\"âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰, {df.shape[1]}ì—´\")\n",
    "\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    if constant_cols:\n",
    "        print(f\"ğŸ“Œ ì œê±°ëœ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼: {constant_cols}\")\n",
    "        df = df.drop(columns=constant_cols)\n",
    "    else:\n",
    "        print(\"ğŸ“Œ ëª¨ë“  ê°’ì´ ë™ì¼í•œ ì¹¼ëŸ¼ ì—†ìŒ\")\n",
    "\n",
    "    col_groups = {}\n",
    "    for col in df.columns:\n",
    "        for key in col_groups:\n",
    "            if df[col].equals(df[key]):\n",
    "                col_groups[key].append(col)\n",
    "                break\n",
    "        else:\n",
    "            col_groups[col] = [col]\n",
    "\n",
    "    duplicate_cols = [col for group in col_groups.values() for col in group[1:]]\n",
    "    if duplicate_cols:\n",
    "        print(f\"ğŸ“Œ ì œê±°ëœ ì¤‘ë³µ ì¹¼ëŸ¼: {duplicate_cols}\")\n",
    "        df = df.drop(columns=duplicate_cols)\n",
    "    else:\n",
    "        print(\"ğŸ“Œ ì¤‘ë³µ ì¹¼ëŸ¼ ì—†ìŒ\")\n",
    "\n",
    "    if 'ID' in df.columns and df.columns.str.contains('ID').sum() > 1:\n",
    "        df = df.loc[:, ~df.columns.str.contains('ID', case=False)].join(df[['ID']])\n",
    "\n",
    "    if 'ê¸°ì¤€ë…„ì›”' in df.columns and df.columns.str.contains('ê¸°ì¤€ë…„ì›”').sum() > 1:\n",
    "        df = df.loc[:, ~df.columns.str.contains('ê¸°ì¤€ë…„ì›”', case=False)].join(df[['ê¸°ì¤€ë…„ì›”']])\n",
    "\n",
    "    print(f\"ğŸ”¹ {file} ì²˜ë¦¬ ì™„ë£Œ. í˜„ì¬ ë°ì´í„° í¬ê¸°: {df.shape[0]}í–‰, {df.shape[1]}ì—´\")\n",
    "\n",
    "new_shape = df.shape\n",
    "output_file = \"./train/base_clean_train.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì›ë˜ ë°ì´í„° í¬ê¸°: {original_shape[0]}í–‰, {original_shape[1]}ì—´\")\n",
    "print(f\"âœ… ë³‘í•© í›„ ìµœì¢… ë°ì´í„° í¬ê¸°: {new_shape[0]}í–‰, {new_shape[1]}ì—´\")\n",
    "print(f\"\\nâœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594b4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ì‹ ìš©ì •ë³´.csv (íŒŒì¼ 2 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 117ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv (íŒŒì¼ 3 / 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\135895452.py:17: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 521ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ì²­êµ¬ì…ê¸ˆì •ë³´.csv (íŒŒì¼ 4 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 565ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ì”ì•¡ì •ë³´.csv (íŒŒì¼ 5 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 645ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ì±„ë„ì •ë³´.csv (íŒŒì¼ 6 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 748ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ë§ˆì¼€íŒ…ì •ë³´.csv (íŒŒì¼ 7 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 810ì—´\n",
      "\n",
      "ğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: test_ì„±ê³¼ì •ë³´.csv (íŒŒì¼ 8 / 8)\n",
      "âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: 600000í–‰, 857ì—´\n",
      "\n",
      "âœ… ì›ë˜ test ë°ì´í„° í¬ê¸°: 600000í–‰, 77ì—´\n",
      "âœ… ë³‘í•© í›„ ìµœì¢… test ë°ì´í„° í¬ê¸°: 600000í–‰, 745ì—´\n",
      "\n",
      "âœ… ìµœì¢… test ë°ì´í„° ì €ì¥ ì™„ë£Œ: ./test/base_clean_test.csv\n",
      "\n",
      "âš ï¸ trainê³¼ testì˜ ì»¬ëŸ¼ì´ ë‹¤ë¦…ë‹ˆë‹¤!\n",
      "ğŸ”¹ trainì—ë§Œ ìˆëŠ” ì»¬ëŸ¼ (1ê°œ): {'Segment'}\n",
      "ğŸ”¹ testì—ë§Œ ìˆëŠ” ì»¬ëŸ¼ (0ê°œ): set()\n"
     ]
    }
   ],
   "source": [
    "test_file_names = [\n",
    "    \"test_íšŒì›ì •ë³´.csv\",\n",
    "    \"test_ì‹ ìš©ì •ë³´.csv\",\n",
    "    \"test_ìŠ¹ì¸ë§¤ì¶œì •ë³´.csv\",\n",
    "    \"test_ì²­êµ¬ì…ê¸ˆì •ë³´.csv\",\n",
    "    \"test_ì”ì•¡ì •ë³´.csv\",\n",
    "    \"test_ì±„ë„ì •ë³´.csv\",\n",
    "    \"test_ë§ˆì¼€íŒ…ì •ë³´.csv\",\n",
    "    \"test_ì„±ê³¼ì •ë³´.csv\"\n",
    "]\n",
    "\n",
    "test_df = pd.read_csv(f\"./test/{categories[0]}/{test_file_names[0]}\")\n",
    "test_original_shape = test_df.shape\n",
    "\n",
    "for idx, file in enumerate(test_file_names[1:], start=2):\n",
    "    print(f\"\\nğŸ”¹ ë³‘í•© ì§„í–‰ ì¤‘: {file} (íŒŒì¼ {idx} / {len(test_file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n",
    "    test_df = test_df.merge(temp_df, how=\"left\", on=[\"ID\", \"ê¸°ì¤€ë…„ì›”\"])\n",
    "    print(f\"âœ… ë³‘í•© í›„ ë°ì´í„° í¬ê¸°: {test_df.shape[0]}í–‰, {test_df.shape[1]}ì—´\")\n",
    "\n",
    "train_df = pd.read_csv(\"./train/base_clean_train.csv\", nrows=1)\n",
    "train_columns = train_df.columns\n",
    "test_columns_to_keep = [col for col in test_df.columns if col in train_columns]\n",
    "\n",
    "test_df = test_df[test_columns_to_keep]\n",
    "test_final_shape = test_df.shape\n",
    "test_output_file = \"./test/base_clean_test.csv\"\n",
    "test_df.to_csv(test_output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì›ë˜ test ë°ì´í„° í¬ê¸°: {test_original_shape[0]}í–‰, {test_original_shape[1]}ì—´\")\n",
    "print(f\"âœ… ë³‘í•© í›„ ìµœì¢… test ë°ì´í„° í¬ê¸°: {test_final_shape[0]}í–‰, {test_final_shape[1]}ì—´\")\n",
    "print(f\"\\nâœ… ìµœì¢… test ë°ì´í„° ì €ì¥ ì™„ë£Œ: {test_output_file}\")\n",
    "\n",
    "train_col_set = set(train_columns)\n",
    "test_col_set = set(test_df.columns)\n",
    "if train_col_set == test_col_set:\n",
    "    print(\"\\nâœ… trainê³¼ testì˜ ì»¬ëŸ¼ì´ ì™„ì „íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    train_only_cols = train_col_set - test_col_set\n",
    "    test_only_cols = test_col_set - train_col_set\n",
    "    print(f\"\\nâš ï¸ trainê³¼ testì˜ ì»¬ëŸ¼ì´ ë‹¤ë¦…ë‹ˆë‹¤!\")\n",
    "    print(f\"ğŸ”¹ trainì—ë§Œ ìˆëŠ” ì»¬ëŸ¼ ({len(train_only_cols)}ê°œ): {train_only_cols}\")\n",
    "    print(f\"ğŸ”¹ testì—ë§Œ ìˆëŠ” ì»¬ëŸ¼ ({len(test_only_cols)}ê°œ): {test_only_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd64399",
   "metadata": {},
   "source": [
    "# Modeling - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298c2432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.8.0+cu126\n",
      "torch.version.cuda: 12.6\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)   # 12.1 ë˜ëŠ” 11.8ì´ì–´ì•¼ í•¨ (Noneì´ë©´ CPU ë¹Œë“œ)\n",
    "print(\"cuda available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3469fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10828\\935452068.py:1: DtypeWarning: Columns (281,355) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('./train/base_clean_train.csv')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10828\\935452068.py:2: DtypeWarning: Columns (280) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('./test/base_clean_test.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Fold 1 training...\n",
      "0:\tlearn: 0.8425386\ttotal: 471ms\tremaining: 11m 45s\n",
      "100:\tlearn: 0.9047615\ttotal: 20.5s\tremaining: 4m 43s\n",
      "200:\tlearn: 0.9178781\ttotal: 39.8s\tremaining: 4m 17s\n",
      "300:\tlearn: 0.9271276\ttotal: 59s\tremaining: 3m 54s\n",
      "400:\tlearn: 0.9338885\ttotal: 1m 18s\tremaining: 3m 34s\n",
      "500:\tlearn: 0.9397080\ttotal: 1m 37s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.9447890\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.9493018\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9527193\ttotal: 2m 33s\tremaining: 2m 14s\n",
      "900:\tlearn: 0.9560647\ttotal: 2m 52s\tremaining: 1m 54s\n",
      "1000:\tlearn: 0.9591432\ttotal: 3m 11s\tremaining: 1m 35s\n",
      "1100:\tlearn: 0.9619612\ttotal: 3m 30s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9645073\ttotal: 3m 49s\tremaining: 57.2s\n",
      "1300:\tlearn: 0.9668168\ttotal: 4m 9s\tremaining: 38.1s\n",
      "1400:\tlearn: 0.9690598\ttotal: 4m 28s\tremaining: 19s\n",
      "1499:\tlearn: 0.9709365\ttotal: 4m 47s\tremaining: 0us\n",
      "ğŸš€ Fold 2 training...\n",
      "0:\tlearn: 0.8425332\ttotal: 526ms\tremaining: 13m 8s\n",
      "100:\tlearn: 0.9043988\ttotal: 20.8s\tremaining: 4m 47s\n",
      "200:\tlearn: 0.9180394\ttotal: 40.3s\tremaining: 4m 20s\n",
      "300:\tlearn: 0.9270312\ttotal: 59.9s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.9340196\ttotal: 1m 19s\tremaining: 3m 37s\n",
      "500:\tlearn: 0.9399271\ttotal: 1m 38s\tremaining: 3m 16s\n",
      "600:\tlearn: 0.9449960\ttotal: 1m 57s\tremaining: 2m 55s\n",
      "700:\tlearn: 0.9493859\ttotal: 2m 17s\tremaining: 2m 36s\n",
      "800:\tlearn: 0.9527436\ttotal: 2m 34s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9562889\ttotal: 2m 53s\tremaining: 1m 55s\n",
      "1000:\tlearn: 0.9591709\ttotal: 3m 12s\tremaining: 1m 35s\n",
      "1100:\tlearn: 0.9617778\ttotal: 3m 30s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9642611\ttotal: 3m 49s\tremaining: 57.1s\n",
      "1300:\tlearn: 0.9664635\ttotal: 4m 7s\tremaining: 37.9s\n",
      "1400:\tlearn: 0.9687289\ttotal: 4m 26s\tremaining: 18.8s\n",
      "1499:\tlearn: 0.9707342\ttotal: 4m 45s\tremaining: 0us\n",
      "ğŸš€ Fold 3 training...\n",
      "0:\tlearn: 0.8426860\ttotal: 493ms\tremaining: 12m 18s\n",
      "100:\tlearn: 0.9045701\ttotal: 20.6s\tremaining: 4m 45s\n",
      "200:\tlearn: 0.9179532\ttotal: 39.1s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9272412\ttotal: 58.8s\tremaining: 3m 54s\n",
      "400:\tlearn: 0.9342107\ttotal: 1m 17s\tremaining: 3m 33s\n",
      "500:\tlearn: 0.9400835\ttotal: 1m 37s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.9453626\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.9499432\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9539701\ttotal: 2m 35s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9572558\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "1000:\tlearn: 0.9601092\ttotal: 3m 14s\tremaining: 1m 36s\n",
      "1100:\tlearn: 0.9630344\ttotal: 3m 34s\tremaining: 1m 17s\n",
      "1200:\tlearn: 0.9656725\ttotal: 3m 53s\tremaining: 58.2s\n",
      "1300:\tlearn: 0.9679385\ttotal: 4m 13s\tremaining: 38.8s\n",
      "1400:\tlearn: 0.9701198\ttotal: 4m 33s\tremaining: 19.3s\n",
      "1499:\tlearn: 0.9721755\ttotal: 4m 52s\tremaining: 0us\n",
      "ğŸš€ Fold 4 training...\n",
      "0:\tlearn: 0.8426603\ttotal: 473ms\tremaining: 11m 49s\n",
      "100:\tlearn: 0.9041164\ttotal: 20.6s\tremaining: 4m 44s\n",
      "200:\tlearn: 0.9176078\ttotal: 40s\tremaining: 4m 18s\n",
      "300:\tlearn: 0.9266643\ttotal: 59.1s\tremaining: 3m 55s\n",
      "400:\tlearn: 0.9336928\ttotal: 1m 18s\tremaining: 3m 35s\n",
      "500:\tlearn: 0.9395504\ttotal: 1m 38s\tremaining: 3m 15s\n",
      "600:\tlearn: 0.9444340\ttotal: 1m 57s\tremaining: 2m 55s\n",
      "700:\tlearn: 0.9487646\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9526735\ttotal: 2m 35s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9560742\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "1000:\tlearn: 0.9586486\ttotal: 3m 12s\tremaining: 1m 36s\n",
      "1100:\tlearn: 0.9614551\ttotal: 3m 31s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9640892\ttotal: 3m 50s\tremaining: 57.4s\n",
      "1300:\tlearn: 0.9664665\ttotal: 4m 9s\tremaining: 38.1s\n",
      "1400:\tlearn: 0.9686899\ttotal: 4m 28s\tremaining: 18.9s\n",
      "1499:\tlearn: 0.9707324\ttotal: 4m 46s\tremaining: 0us\n",
      "ğŸš€ Fold 5 training...\n",
      "0:\tlearn: 0.8423167\ttotal: 498ms\tremaining: 12m 26s\n",
      "100:\tlearn: 0.9044024\ttotal: 20.5s\tremaining: 4m 43s\n",
      "200:\tlearn: 0.9176462\ttotal: 40.2s\tremaining: 4m 19s\n",
      "300:\tlearn: 0.9268466\ttotal: 59.3s\tremaining: 3m 56s\n",
      "400:\tlearn: 0.9340366\ttotal: 1m 18s\tremaining: 3m 35s\n",
      "500:\tlearn: 0.9399004\ttotal: 1m 37s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.9449794\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.9494178\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9528307\ttotal: 2m 35s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9563497\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "1000:\tlearn: 0.9595126\ttotal: 3m 13s\tremaining: 1m 36s\n",
      "1100:\tlearn: 0.9623773\ttotal: 3m 32s\tremaining: 1m 17s\n",
      "1200:\tlearn: 0.9649621\ttotal: 3m 52s\tremaining: 57.9s\n",
      "1300:\tlearn: 0.9673960\ttotal: 4m 11s\tremaining: 38.5s\n",
      "1400:\tlearn: 0.9695366\ttotal: 4m 31s\tremaining: 19.2s\n",
      "1499:\tlearn: 0.9716132\ttotal: 4m 50s\tremaining: 0us\n",
      "ğŸš€ Fold 6 training...\n",
      "0:\tlearn: 0.8424855\ttotal: 397ms\tremaining: 9m 54s\n",
      "100:\tlearn: 0.9042097\ttotal: 20s\tremaining: 4m 37s\n",
      "200:\tlearn: 0.9182806\ttotal: 39s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9270824\ttotal: 58s\tremaining: 3m 50s\n",
      "400:\tlearn: 0.9341902\ttotal: 1m 16s\tremaining: 3m 30s\n",
      "500:\tlearn: 0.9398708\ttotal: 1m 35s\tremaining: 3m 10s\n",
      "600:\tlearn: 0.9450650\ttotal: 1m 54s\tremaining: 2m 51s\n",
      "700:\tlearn: 0.9494845\ttotal: 2m 13s\tremaining: 2m 32s\n",
      "800:\tlearn: 0.9536105\ttotal: 2m 32s\tremaining: 2m 13s\n",
      "900:\tlearn: 0.9569970\ttotal: 2m 51s\tremaining: 1m 53s\n",
      "1000:\tlearn: 0.9599590\ttotal: 3m 10s\tremaining: 1m 34s\n",
      "1100:\tlearn: 0.9627202\ttotal: 3m 28s\tremaining: 1m 15s\n",
      "1200:\tlearn: 0.9653036\ttotal: 3m 47s\tremaining: 56.7s\n",
      "1300:\tlearn: 0.9676975\ttotal: 4m 6s\tremaining: 37.8s\n",
      "1400:\tlearn: 0.9695956\ttotal: 4m 25s\tremaining: 18.7s\n",
      "1499:\tlearn: 0.9714685\ttotal: 4m 44s\tremaining: 0us\n",
      "ğŸš€ Fold 7 training...\n",
      "0:\tlearn: 0.8424702\ttotal: 479ms\tremaining: 11m 58s\n",
      "100:\tlearn: 0.9045393\ttotal: 20.4s\tremaining: 4m 42s\n",
      "200:\tlearn: 0.9180739\ttotal: 39.1s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9269841\ttotal: 57.8s\tremaining: 3m 50s\n",
      "400:\tlearn: 0.9339369\ttotal: 1m 16s\tremaining: 3m 28s\n",
      "500:\tlearn: 0.9398656\ttotal: 1m 34s\tremaining: 3m 9s\n",
      "600:\tlearn: 0.9448688\ttotal: 1m 53s\tremaining: 2m 50s\n",
      "700:\tlearn: 0.9493509\ttotal: 2m 12s\tremaining: 2m 31s\n",
      "800:\tlearn: 0.9528888\ttotal: 2m 31s\tremaining: 2m 11s\n",
      "900:\tlearn: 0.9548967\ttotal: 2m 46s\tremaining: 1m 51s\n",
      "1000:\tlearn: 0.9581213\ttotal: 3m 5s\tremaining: 1m 32s\n",
      "1100:\tlearn: 0.9607655\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9634992\ttotal: 3m 43s\tremaining: 55.6s\n",
      "1300:\tlearn: 0.9660996\ttotal: 4m 2s\tremaining: 37.1s\n",
      "1400:\tlearn: 0.9684261\ttotal: 4m 22s\tremaining: 18.5s\n",
      "1499:\tlearn: 0.9705265\ttotal: 4m 41s\tremaining: 0us\n",
      "ğŸš€ Fold 8 training...\n",
      "0:\tlearn: 0.8424734\ttotal: 461ms\tremaining: 11m 30s\n",
      "100:\tlearn: 0.9043580\ttotal: 20.1s\tremaining: 4m 38s\n",
      "200:\tlearn: 0.9178630\ttotal: 38.6s\tremaining: 4m 9s\n",
      "300:\tlearn: 0.9270163\ttotal: 57.6s\tremaining: 3m 49s\n",
      "400:\tlearn: 0.9342272\ttotal: 1m 16s\tremaining: 3m 29s\n",
      "500:\tlearn: 0.9400690\ttotal: 1m 35s\tremaining: 3m 10s\n",
      "600:\tlearn: 0.9451051\ttotal: 1m 54s\tremaining: 2m 50s\n",
      "700:\tlearn: 0.9495942\ttotal: 2m 13s\tremaining: 2m 31s\n",
      "800:\tlearn: 0.9533284\ttotal: 2m 32s\tremaining: 2m 12s\n",
      "900:\tlearn: 0.9560002\ttotal: 2m 49s\tremaining: 1m 52s\n",
      "1000:\tlearn: 0.9593109\ttotal: 3m 8s\tremaining: 1m 33s\n",
      "1100:\tlearn: 0.9618303\ttotal: 3m 26s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9642777\ttotal: 3m 44s\tremaining: 56s\n",
      "1300:\tlearn: 0.9663189\ttotal: 4m 3s\tremaining: 37.2s\n",
      "1400:\tlearn: 0.9684567\ttotal: 4m 21s\tremaining: 18.5s\n",
      "1499:\tlearn: 0.9703993\ttotal: 4m 40s\tremaining: 0us\n",
      "ğŸš€ Fold 9 training...\n",
      "0:\tlearn: 0.8425640\ttotal: 548ms\tremaining: 13m 41s\n",
      "100:\tlearn: 0.9044450\ttotal: 20.9s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.9179953\ttotal: 40.5s\tremaining: 4m 22s\n",
      "300:\tlearn: 0.9269375\ttotal: 60s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.9340943\ttotal: 1m 19s\tremaining: 3m 38s\n",
      "500:\tlearn: 0.9400001\ttotal: 1m 39s\tremaining: 3m 17s\n",
      "600:\tlearn: 0.9448799\ttotal: 1m 58s\tremaining: 2m 57s\n",
      "700:\tlearn: 0.9493197\ttotal: 2m 18s\tremaining: 2m 37s\n",
      "800:\tlearn: 0.9532658\ttotal: 2m 38s\tremaining: 2m 17s\n",
      "900:\tlearn: 0.9567788\ttotal: 2m 57s\tremaining: 1m 58s\n",
      "1000:\tlearn: 0.9598023\ttotal: 3m 17s\tremaining: 1m 38s\n",
      "1100:\tlearn: 0.9627275\ttotal: 3m 36s\tremaining: 1m 18s\n",
      "1200:\tlearn: 0.9652777\ttotal: 3m 56s\tremaining: 58.8s\n",
      "1300:\tlearn: 0.9676854\ttotal: 4m 16s\tremaining: 39.2s\n",
      "1400:\tlearn: 0.9698594\ttotal: 4m 36s\tremaining: 19.5s\n",
      "1499:\tlearn: 0.9718434\ttotal: 4m 55s\tremaining: 0us\n",
      "ğŸš€ Fold 10 training...\n",
      "0:\tlearn: 0.8425672\ttotal: 529ms\tremaining: 13m 12s\n",
      "100:\tlearn: 0.9045408\ttotal: 20.8s\tremaining: 4m 47s\n",
      "200:\tlearn: 0.9180421\ttotal: 40.3s\tremaining: 4m 20s\n",
      "300:\tlearn: 0.9270589\ttotal: 60s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.9344468\ttotal: 1m 19s\tremaining: 3m 37s\n",
      "500:\tlearn: 0.9401405\ttotal: 1m 38s\tremaining: 3m 16s\n",
      "600:\tlearn: 0.9452368\ttotal: 1m 58s\tremaining: 2m 56s\n",
      "700:\tlearn: 0.9496597\ttotal: 2m 17s\tremaining: 2m 36s\n",
      "800:\tlearn: 0.9536272\ttotal: 2m 37s\tremaining: 2m 17s\n",
      "900:\tlearn: 0.9570600\ttotal: 2m 56s\tremaining: 1m 57s\n",
      "1000:\tlearn: 0.9602073\ttotal: 3m 16s\tremaining: 1m 37s\n",
      "1100:\tlearn: 0.9630984\ttotal: 3m 36s\tremaining: 1m 18s\n",
      "1200:\tlearn: 0.9655991\ttotal: 3m 55s\tremaining: 58.6s\n",
      "1300:\tlearn: 0.9677257\ttotal: 4m 14s\tremaining: 39s\n",
      "1400:\tlearn: 0.9696679\ttotal: 4m 34s\tremaining: 19.4s\n",
      "1499:\tlearn: 0.9715540\ttotal: 4m 53s\tremaining: 0us\n",
      "âœ… CatBoost + 10-Fold CV ì˜ˆì¸¡ ì™„ë£Œ ë° ì €ì¥ ğŸ¯\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/base_clean_train.csv')\n",
    "test = pd.read_csv('./test/base_clean_test.csv')\n",
    "\n",
    "ab_ids = train[train['Segment'].isin(['A', 'B'])]['ID'].unique()\n",
    "train = train[~train['ID'].isin(ab_ids)].copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "best_params = {\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"learning_rate\": 0.2997682904093563,\n",
    "    \"l2_leaf_reg\": 9.214022161348987,\n",
    "    \"random_strength\": 7.342192789415524,\n",
    "    \"bagging_temperature\": 0.11417356499443036,\n",
    "    \"border_count\": 251,\n",
    "    \"iterations\": 1500,\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"eval_metric\": \"TotalF1\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"verbose\": 100,\n",
    "    \"random_seed\": 42,\n",
    "    \"depth\": 8,\n",
    "    \"class_weights\": [2, 1, 1]\n",
    "}\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"ğŸš€ Fold {fold+1} training...\")\n",
    "    X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    model = CatBoostClassifier(**best_params)\n",
    "    model.fit(X_train_fold, y_train_fold, cat_features=cat_features)\n",
    "    fold_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += fold_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=range(n_classes))\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs.drop(columns='ID').values.argmax(axis=1)\n",
    "segment_mapping = {0: 'C', 1: 'D', 2: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "submission = pd.DataFrame({'ID': mean_probs['ID'], 'Segment': mean_probs['Segment']})\n",
    "submission.to_csv('./test/base_catboost_kfold.csv', index=False)\n",
    "print(\"âœ… CatBoost + 10-Fold CV ì˜ˆì¸¡ ì™„ë£Œ ë° ì €ì¥ ğŸ¯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50fdd9",
   "metadata": {},
   "source": [
    "# Data Preprocessing - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30ae1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2696\\216419294.py:1: DtypeWarning: Columns (281,355) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('./train/base_clean_train.csv')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2696\\216419294.py:2: DtypeWarning: Columns (280) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('./test/base_clean_test.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ ê³ ì •ëœ ì¹¼ëŸ¼ 83ê°œ ì œê±°í•  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
      "ğŸš€ ìµœì¢… train ë°ì´í„° shape: (249594, 663)\n",
      "ğŸš€ ìµœì¢… test ë°ì´í„° shape: (62586, 662)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/base_clean_train.csv')\n",
    "test = pd.read_csv('./test/base_clean_test.csv')\n",
    "\n",
    "train_A = train[train['Segment'] == 'A']\n",
    "cols_to_check = [col for col in train.columns if col not in ['ID', 'Segment']]\n",
    "\n",
    "def is_fixed_column(df, col):\n",
    "    return df[col].nunique() == 1\n",
    "\n",
    "fixed_columns_A = {col: train_A[col].iloc[0] for col in cols_to_check if is_fixed_column(train_A, col)}\n",
    "fixed_cols = list(fixed_columns_A.keys())\n",
    "print(f\"ğŸ“¦ ê³ ì •ëœ ì¹¼ëŸ¼ {len(fixed_cols)}ê°œ ì œê±°í•  ì˜ˆì •ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "matching_ids_train = train.copy()\n",
    "for col, value in fixed_columns_A.items():\n",
    "    matching_ids_train = matching_ids_train[matching_ids_train[col] == value]\n",
    "matching_ids_train_list = matching_ids_train.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "matching_ids_test = test.copy()\n",
    "for col, value in fixed_columns_A.items():\n",
    "    matching_ids_test = matching_ids_test[matching_ids_test[col] == value]\n",
    "matching_ids_test_list = matching_ids_test.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "train_filtered = train[train['ID'].isin(matching_ids_train_list)].drop(columns=fixed_cols)\n",
    "test_filtered = test[test['ID'].isin(matching_ids_test_list)].drop(columns=fixed_cols)\n",
    "\n",
    "print(f\"ğŸš€ ìµœì¢… train ë°ì´í„° shape: {train_filtered.shape}\")\n",
    "print(f\"ğŸš€ ìµœì¢… test ë°ì´í„° shape: {test_filtered.shape}\")\n",
    "train_filtered.to_csv('./train/train_vips_A.csv', index=False)\n",
    "test_filtered.to_csv('./test/test_vips_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd833566",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train/base_clean_train.csv')\n",
    "test = pd.read_csv('./test/base_clean_test.csv')\n",
    "\n",
    "train_B = train[train['Segment'] == 'B']\n",
    "cols_to_check = [col for col in train.columns if col not in ['ID', 'Segment']]\n",
    "\n",
    "fixed_columns_B = {col: train_B[col].iloc[0] for col in cols_to_check if is_fixed_column(train_B, col)}\n",
    "fixed_cols = list(fixed_columns_B.keys())\n",
    "print(f\"ğŸ“¦ ê³ ì •ëœ ì¹¼ëŸ¼ {len(fixed_cols)}ê°œ ì œê±°í•  ì˜ˆì •ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "matching_ids_train = train.copy()\n",
    "for col, value in fixed_columns_B.items():\n",
    "    matching_ids_train = matching_ids_train[matching_ids_train[col] == value]\n",
    "matching_ids_train_list = matching_ids_train.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "matching_ids_test = test.copy()\n",
    "for col, value in fixed_columns_B.items():\n",
    "    matching_ids_test = matching_ids_test[matching_ids_test[col] == value]\n",
    "matching_ids_test_list = matching_ids_test.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "train_filtered = train[train['ID'].isin(matching_ids_train_list)].drop(columns=fixed_cols)\n",
    "test_filtered = test[test['ID'].isin(matching_ids_test_list)].drop(columns=fixed_cols)\n",
    "\n",
    "print(f\"ğŸš€ ìµœì¢… train ë°ì´í„° shape: {train_filtered.shape}\")\n",
    "print(f\"ğŸš€ ìµœì¢… test ë°ì´í„° shape: {test_filtered.shape}\")\n",
    "train_filtered.to_csv('./train/train_vips_B.csv', index=False)\n",
    "test_filtered.to_csv('./test/test_vips_B.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ed0bc",
   "metadata": {},
   "source": [
    "# Modeling - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89890ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m./train/train_vips_A.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m./test/test_vips_A.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m label_encoder = LabelEncoder()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/train_vips_A.csv')\n",
    "test = pd.read_csv('./test/test_vips_A.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'task_type': 'GPU',\n",
    "    'class_weights': [20, 50, 2, 1, 1],\n",
    "}\n",
    "\n",
    "n_classes = 5\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nğŸš€ ë‹¨ì¼ Model Run ì‹œì‘\")\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"ğŸ“‚ Fold {fold + 1}\")\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=(X_valid_fold, y_valid_fold),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += test_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=[0, 1, 2, 3, 4])\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs[[0, 1, 2, 3, 4]].idxmax(axis=1)\n",
    "segment_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "a_ids = mean_probs.loc[mean_probs['Segment'] == 'A', 'ID'].tolist()\n",
    "print(f\"\\nâœ… Aë¡œ ë¶„ë¥˜ëœ ID ìˆ˜ = {len(a_ids)}ê°œ\")\n",
    "print(f\"ğŸ” A ID: {a_ids[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc55e3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m./train/train_vips_B.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m./test/test_vips_B.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m label_encoder = LabelEncoder()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/train_vips_B.csv')\n",
    "test = pd.read_csv('./test/test_vips_B.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'task_type': 'GPU',\n",
    "    'class_weights': [10, 10, 1, 1, 1],\n",
    "}\n",
    "\n",
    "n_classes = 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\nğŸš€ ë‹¨ì¼ Model Run ì‹œì‘\")\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"ğŸ“‚ Fold {fold + 1}\")\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=(X_valid_fold, y_valid_fold),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += test_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=[0, 1, 2, 3, 4])\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs[[0, 1, 2, 3, 4]].idxmax(axis=1)\n",
    "segment_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "b_ids = mean_probs.loc[mean_probs['Segment'] == 'B', 'ID'].tolist()\n",
    "print(f\"\\nâœ… Bë¡œ ë¶„ë¥˜ëœ ID ìˆ˜ = {len(b_ids)}ê°œ\")\n",
    "print(f\"ğŸ” B ID: {b_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5fae76",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv('./test/base_catboost_kfold.csv')\n",
    "base_df.loc[base_df['ID'].isin(a_ids), 'Segment'] = 'A'\n",
    "base_df.loc[base_df['ID'].isin(b_ids), 'Segment'] = 'B'\n",
    "base_df.to_csv('./test/final_catboost.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Segmentê°€ 'A'ë¡œ ìˆ˜ì •ëœ {len(a_ids)}ê°œ ID ë°˜ì˜ ì™„ë£Œ\")\n",
    "print(f\"âœ… Segmentê°€ 'B'ë¡œ ìˆ˜ì •ëœ {len(b_ids)}ê°œ ID ë°˜ì˜ ì™„ë£Œ\")\n",
    "print(\"ğŸ¯ ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: final_catboost.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

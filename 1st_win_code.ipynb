{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b659824f",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740cd8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\envs\\ML\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import optuna\n",
    "import os\n",
    "import json\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b52e81",
   "metadata": {},
   "source": [
    "# Data Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d0935bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ./train/회원정보/201807_train_회원정보.parquet 변환 완료\n",
      "✅ ./train/회원정보/201808_train_회원정보.parquet 변환 완료\n",
      "✅ ./train/회원정보/201809_train_회원정보.parquet 변환 완료\n",
      "✅ ./train/회원정보/201810_train_회원정보.parquet 변환 완료\n",
      "✅ ./train/회원정보/201811_train_회원정보.parquet 변환 완료\n",
      "✅ ./train/회원정보/201812_train_회원정보.parquet 변환 완료\n",
      "✅ ./train/회원정보/train_회원정보.csv 저장 완료 (Shape: (2400000, 78))\n",
      "✅ ./train/신용정보/201807_train_신용정보.parquet 변환 완료\n",
      "✅ ./train/신용정보/201808_train_신용정보.parquet 변환 완료\n",
      "✅ ./train/신용정보/201809_train_신용정보.parquet 변환 완료\n",
      "✅ ./train/신용정보/201810_train_신용정보.parquet 변환 완료\n",
      "✅ ./train/신용정보/201811_train_신용정보.parquet 변환 완료\n",
      "✅ ./train/신용정보/201812_train_신용정보.parquet 변환 완료\n",
      "✅ ./train/신용정보/train_신용정보.csv 저장 완료 (Shape: (2400000, 42))\n",
      "✅ ./train/승인매출정보/201807_train_승인매출정보.parquet 변환 완료\n",
      "✅ ./train/승인매출정보/201808_train_승인매출정보.parquet 변환 완료\n",
      "✅ ./train/승인매출정보/201809_train_승인매출정보.parquet 변환 완료\n",
      "✅ ./train/승인매출정보/201810_train_승인매출정보.parquet 변환 완료\n",
      "✅ ./train/승인매출정보/201811_train_승인매출정보.parquet 변환 완료\n",
      "✅ ./train/승인매출정보/201812_train_승인매출정보.parquet 변환 완료\n",
      "✅ ./train/승인매출정보/train_승인매출정보.csv 저장 완료 (Shape: (2400000, 406))\n",
      "✅ ./train/청구입금정보/201807_train_청구입금정보.parquet 변환 완료\n",
      "✅ ./train/청구입금정보/201808_train_청구입금정보.parquet 변환 완료\n",
      "✅ ./train/청구입금정보/201809_train_청구입금정보.parquet 변환 완료\n",
      "✅ ./train/청구입금정보/201810_train_청구입금정보.parquet 변환 완료\n",
      "✅ ./train/청구입금정보/201811_train_청구입금정보.parquet 변환 완료\n",
      "✅ ./train/청구입금정보/201812_train_청구입금정보.parquet 변환 완료\n",
      "✅ ./train/청구입금정보/train_청구입금정보.csv 저장 완료 (Shape: (2400000, 46))\n",
      "✅ ./train/잔액정보/201807_train_잔액정보.parquet 변환 완료\n",
      "✅ ./train/잔액정보/201808_train_잔액정보.parquet 변환 완료\n",
      "✅ ./train/잔액정보/201809_train_잔액정보.parquet 변환 완료\n",
      "✅ ./train/잔액정보/201810_train_잔액정보.parquet 변환 완료\n",
      "✅ ./train/잔액정보/201811_train_잔액정보.parquet 변환 완료\n",
      "✅ ./train/잔액정보/201812_train_잔액정보.parquet 변환 완료\n",
      "✅ ./train/잔액정보/train_잔액정보.csv 저장 완료 (Shape: (2400000, 82))\n",
      "✅ ./train/채널정보/201807_train_채널정보.parquet 변환 완료\n",
      "✅ ./train/채널정보/201808_train_채널정보.parquet 변환 완료\n",
      "✅ ./train/채널정보/201809_train_채널정보.parquet 변환 완료\n",
      "✅ ./train/채널정보/201810_train_채널정보.parquet 변환 완료\n",
      "✅ ./train/채널정보/201811_train_채널정보.parquet 변환 완료\n",
      "✅ ./train/채널정보/201812_train_채널정보.parquet 변환 완료\n",
      "✅ ./train/채널정보/train_채널정보.csv 저장 완료 (Shape: (2400000, 105))\n",
      "✅ ./train/마케팅정보/201807_train_마케팅정보.parquet 변환 완료\n",
      "✅ ./train/마케팅정보/201808_train_마케팅정보.parquet 변환 완료\n",
      "✅ ./train/마케팅정보/201809_train_마케팅정보.parquet 변환 완료\n",
      "✅ ./train/마케팅정보/201810_train_마케팅정보.parquet 변환 완료\n",
      "✅ ./train/마케팅정보/201811_train_마케팅정보.parquet 변환 완료\n",
      "✅ ./train/마케팅정보/201812_train_마케팅정보.parquet 변환 완료\n",
      "✅ ./train/마케팅정보/train_마케팅정보.csv 저장 완료 (Shape: (2400000, 64))\n",
      "✅ ./train/성과정보/201807_train_성과정보.parquet 변환 완료\n",
      "✅ ./train/성과정보/201808_train_성과정보.parquet 변환 완료\n",
      "✅ ./train/성과정보/201809_train_성과정보.parquet 변환 완료\n",
      "✅ ./train/성과정보/201810_train_성과정보.parquet 변환 완료\n",
      "✅ ./train/성과정보/201811_train_성과정보.parquet 변환 완료\n",
      "✅ ./train/성과정보/201812_train_성과정보.parquet 변환 완료\n",
      "✅ ./train/성과정보/train_성과정보.csv 저장 완료 (Shape: (2400000, 49))\n",
      "✅ ./test/회원정보/201807_test_회원정보.parquet 변환 완료\n",
      "✅ ./test/회원정보/201808_test_회원정보.parquet 변환 완료\n",
      "✅ ./test/회원정보/201809_test_회원정보.parquet 변환 완료\n",
      "✅ ./test/회원정보/201810_test_회원정보.parquet 변환 완료\n",
      "✅ ./test/회원정보/201811_test_회원정보.parquet 변환 완료\n",
      "✅ ./test/회원정보/201812_test_회원정보.parquet 변환 완료\n",
      "✅ ./test/회원정보/test_회원정보.csv 저장 완료 (Shape: (600000, 77))\n",
      "✅ ./test/신용정보/201807_test_신용정보.parquet 변환 완료\n",
      "✅ ./test/신용정보/201808_test_신용정보.parquet 변환 완료\n",
      "✅ ./test/신용정보/201809_test_신용정보.parquet 변환 완료\n",
      "✅ ./test/신용정보/201810_test_신용정보.parquet 변환 완료\n",
      "✅ ./test/신용정보/201811_test_신용정보.parquet 변환 완료\n",
      "✅ ./test/신용정보/201812_test_신용정보.parquet 변환 완료\n",
      "✅ ./test/신용정보/test_신용정보.csv 저장 완료 (Shape: (600000, 42))\n",
      "✅ ./test/승인매출정보/201807_test_승인매출정보.parquet 변환 완료\n",
      "✅ ./test/승인매출정보/201808_test_승인매출정보.parquet 변환 완료\n",
      "✅ ./test/승인매출정보/201809_test_승인매출정보.parquet 변환 완료\n",
      "✅ ./test/승인매출정보/201810_test_승인매출정보.parquet 변환 완료\n",
      "✅ ./test/승인매출정보/201811_test_승인매출정보.parquet 변환 완료\n",
      "✅ ./test/승인매출정보/201812_test_승인매출정보.parquet 변환 완료\n",
      "✅ ./test/승인매출정보/test_승인매출정보.csv 저장 완료 (Shape: (600000, 406))\n",
      "✅ ./test/청구입금정보/201807_test_청구입금정보.parquet 변환 완료\n",
      "✅ ./test/청구입금정보/201808_test_청구입금정보.parquet 변환 완료\n",
      "✅ ./test/청구입금정보/201809_test_청구입금정보.parquet 변환 완료\n",
      "✅ ./test/청구입금정보/201810_test_청구입금정보.parquet 변환 완료\n",
      "✅ ./test/청구입금정보/201811_test_청구입금정보.parquet 변환 완료\n",
      "✅ ./test/청구입금정보/201812_test_청구입금정보.parquet 변환 완료\n",
      "✅ ./test/청구입금정보/test_청구입금정보.csv 저장 완료 (Shape: (600000, 46))\n",
      "✅ ./test/잔액정보/201807_test_잔액정보.parquet 변환 완료\n",
      "✅ ./test/잔액정보/201808_test_잔액정보.parquet 변환 완료\n",
      "✅ ./test/잔액정보/201809_test_잔액정보.parquet 변환 완료\n",
      "✅ ./test/잔액정보/201810_test_잔액정보.parquet 변환 완료\n",
      "✅ ./test/잔액정보/201811_test_잔액정보.parquet 변환 완료\n",
      "✅ ./test/잔액정보/201812_test_잔액정보.parquet 변환 완료\n",
      "✅ ./test/잔액정보/test_잔액정보.csv 저장 완료 (Shape: (600000, 82))\n",
      "✅ ./test/채널정보/201807_test_채널정보.parquet 변환 완료\n",
      "✅ ./test/채널정보/201808_test_채널정보.parquet 변환 완료\n",
      "✅ ./test/채널정보/201809_test_채널정보.parquet 변환 완료\n",
      "✅ ./test/채널정보/201810_test_채널정보.parquet 변환 완료\n",
      "✅ ./test/채널정보/201811_test_채널정보.parquet 변환 완료\n",
      "✅ ./test/채널정보/201812_test_채널정보.parquet 변환 완료\n",
      "✅ ./test/채널정보/test_채널정보.csv 저장 완료 (Shape: (600000, 105))\n",
      "✅ ./test/마케팅정보/201807_test_마케팅정보.parquet 변환 완료\n",
      "✅ ./test/마케팅정보/201808_test_마케팅정보.parquet 변환 완료\n",
      "✅ ./test/마케팅정보/201809_test_마케팅정보.parquet 변환 완료\n",
      "✅ ./test/마케팅정보/201810_test_마케팅정보.parquet 변환 완료\n",
      "✅ ./test/마케팅정보/201811_test_마케팅정보.parquet 변환 완료\n",
      "✅ ./test/마케팅정보/201812_test_마케팅정보.parquet 변환 완료\n",
      "✅ ./test/마케팅정보/test_마케팅정보.csv 저장 완료 (Shape: (600000, 64))\n",
      "✅ ./test/성과정보/201807_test_성과정보.parquet 변환 완료\n",
      "✅ ./test/성과정보/201808_test_성과정보.parquet 변환 완료\n",
      "✅ ./test/성과정보/201809_test_성과정보.parquet 변환 완료\n",
      "✅ ./test/성과정보/201810_test_성과정보.parquet 변환 완료\n",
      "✅ ./test/성과정보/201811_test_성과정보.parquet 변환 완료\n",
      "✅ ./test/성과정보/201812_test_성과정보.parquet 변환 완료\n",
      "✅ ./test/성과정보/test_성과정보.csv 저장 완료 (Shape: (600000, 49))\n"
     ]
    }
   ],
   "source": [
    "months = [\"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "categories = [\"회원정보\", \"신용정보\", \"승인매출정보\", \"청구입금정보\", \"잔액정보\", \"채널정보\", \"마케팅정보\", \"성과정보\"]\n",
    "data_types = [\"train\", \"test\"]\n",
    "\n",
    "def merge_monthly_data(data_type, category):\n",
    "    merged_list = []\n",
    "    for month in months:\n",
    "        file_name = f\"./{data_type}/{category}/2018{month}_{data_type}_{category}.parquet\"\n",
    "        try:\n",
    "            df = pd.read_parquet(file_name, engine=\"pyarrow\")\n",
    "            merged_list.append(df)\n",
    "            print(f\"✅ {file_name} 변환 완료\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"⚠️ 파일 없음: {file_name}\")\n",
    "    if merged_list:\n",
    "        merged_df = pd.concat(merged_list, ignore_index=True)\n",
    "        output_file = f\"./{data_type}/{category}/{data_type}_{category}.csv\"\n",
    "        merged_df.to_csv(output_file, index=False)\n",
    "        print(f\"✅ {output_file} 저장 완료 (Shape: {merged_df.shape})\")\n",
    "    else:\n",
    "        print(f\"❌ {data_type}_{category} 데이터 없음\")\n",
    "\n",
    "for data_type in data_types:\n",
    "    for category in categories:\n",
    "        merge_monthly_data(data_type, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f515f",
   "metadata": {},
   "source": [
    "# Data Transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c1b794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 병합 중: train_신용정보.csv (2/8)\n",
      "✅ 병합 후 크기: (2400000, 118)\n",
      "\n",
      "🔹 병합 중: train_승인매출정보.csv (3/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\1239001571.py:15: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 후 크기: (2400000, 522)\n",
      "\n",
      "🔹 병합 중: train_청구입금정보.csv (4/8)\n",
      "✅ 병합 후 크기: (2400000, 566)\n",
      "\n",
      "🔹 병합 중: train_잔액정보.csv (5/8)\n",
      "✅ 병합 후 크기: (2400000, 646)\n",
      "\n",
      "🔹 병합 중: train_채널정보.csv (6/8)\n",
      "✅ 병합 후 크기: (2400000, 749)\n",
      "\n",
      "🔹 병합 중: train_마케팅정보.csv (7/8)\n",
      "✅ 병합 후 크기: (2400000, 811)\n",
      "\n",
      "🔹 병합 중: train_성과정보.csv (8/8)\n",
      "✅ 병합 후 크기: (2400000, 858)\n",
      "\n",
      "✅ 최종 데이터 저장 완료: ./train/base_train.csv\n",
      "🧾 최종 데이터 크기: 2400000행, 858열\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"train_회원정보.csv\",\n",
    "    \"train_신용정보.csv\",\n",
    "    \"train_승인매출정보.csv\",\n",
    "    \"train_청구입금정보.csv\",\n",
    "    \"train_잔액정보.csv\",\n",
    "    \"train_채널정보.csv\",\n",
    "    \"train_마케팅정보.csv\",\n",
    "    \"train_성과정보.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f\"./train/{categories[0]}/{file_names[0]}\")\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 중: {file} ({idx}/{len(file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 크기: {df.shape}\")\n",
    "\n",
    "output_file = \"./train/base_train.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ 최종 데이터 저장 완료: {output_file}\")\n",
    "print(f\"🧾 최종 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f51dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 병합 중: test_신용정보.csv (2/8)\n",
      "✅ 병합 후 크기: (600000, 117)\n",
      "\n",
      "🔹 병합 중: test_승인매출정보.csv (3/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\879322153.py:15: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 후 크기: (600000, 521)\n",
      "\n",
      "🔹 병합 중: test_청구입금정보.csv (4/8)\n",
      "✅ 병합 후 크기: (600000, 565)\n",
      "\n",
      "🔹 병합 중: test_잔액정보.csv (5/8)\n",
      "✅ 병합 후 크기: (600000, 645)\n",
      "\n",
      "🔹 병합 중: test_채널정보.csv (6/8)\n",
      "✅ 병합 후 크기: (600000, 748)\n",
      "\n",
      "🔹 병합 중: test_마케팅정보.csv (7/8)\n",
      "✅ 병합 후 크기: (600000, 810)\n",
      "\n",
      "🔹 병합 중: test_성과정보.csv (8/8)\n",
      "✅ 병합 후 크기: (600000, 857)\n",
      "\n",
      "✅ 최종 데이터 저장 완료: ./test/base_test.csv\n",
      "🧾 최종 데이터 크기: 600000행, 857열\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"test_회원정보.csv\",\n",
    "    \"test_신용정보.csv\",\n",
    "    \"test_승인매출정보.csv\",\n",
    "    \"test_청구입금정보.csv\",\n",
    "    \"test_잔액정보.csv\",\n",
    "    \"test_채널정보.csv\",\n",
    "    \"test_마케팅정보.csv\",\n",
    "    \"test_성과정보.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f\"./test/{categories[0]}/{file_names[0]}\")\n",
    "for idx, file in enumerate(file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 중: {file} ({idx}/{len(file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 크기: {df.shape}\")\n",
    "\n",
    "output_file = \"./test/base_test.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✅ 최종 데이터 저장 완료: {output_file}\")\n",
    "print(f\"🧾 최종 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6f695a",
   "metadata": {},
   "source": [
    "# Data Preprocessing - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8413743c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 병합 진행 중: train_신용정보.csv (파일 2 / 8)\n",
      "✅ 병합 후 데이터 크기: 2400000행, 118열\n",
      "📌 제거된 모든 값이 동일한 칼럼: ['이용카드수_체크_가족', '이용금액_R3M_체크_가족', '연회비할인카드수_B0M', '할인금액_기본연회비_B0M', '할인금액_제휴연회비_B0M', '상품관련면제카드수_B0M', '임직원면제카드수_B0M', '우수회원면제카드수_B0M', '기타면제카드수_B0M', '시장연체상환여부_R3M']\n",
      "📌 제거된 중복 칼럼: ['청구금액_기본연회비_B0M', '청구금액_제휴연회비_B0M']\n",
      "🔹 train_신용정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 106열\n",
      "\n",
      "🔹 병합 진행 중: train_승인매출정보.csv (파일 3 / 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\4271029770.py:17: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 후 데이터 크기: 2400000행, 510열\n",
      "📌 제거된 모든 값이 동일한 칼럼: ['이용건수_부분무이자_B0M', '이용금액_부분무이자_B0M', '여유_여행이용금액', '납부_렌탈료이용금액', '납부_유선방송이용금액', '납부_건강연금이용금액', '할부건수_부분_3M_R12M', '할부건수_부분_6M_R12M', '할부건수_부분_14M_R12M', '할부금액_부분_3M_R12M', 'RP건수_유선방송_B0M', 'RP건수_건강_B0M', 'RP후경과월_유선방송', 'RP후경과월_건강', '증감_RP건수_유선방송_전월', '증감_RP건수_건강_전월', '이용개월수_당사페이_R6M', '이용금액_당사페이_R6M', '이용금액_당사기타_R6M', '이용건수_당사페이_R6M', '이용건수_당사기타_R6M', '이용금액_당사페이_R3M', '이용금액_당사기타_R3M', '이용건수_당사페이_R3M', '이용건수_당사기타_R3M', '이용금액_당사페이_B0M', '이용금액_당사기타_B0M', '이용건수_당사페이_B0M', '이용건수_당사기타_B0M', '승인거절건수_입력오류_B0M', '승인거절건수_기타_B0M']\n",
      "📌 제거된 중복 칼럼: ['이용횟수_연체_B0M', '할부건수_부분_12M_R12M']\n",
      "🔹 train_승인매출정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 477열\n",
      "\n",
      "🔹 병합 진행 중: train_청구입금정보.csv (파일 4 / 8)\n",
      "✅ 병합 후 데이터 크기: 2400000행, 521열\n",
      "📌 제거된 모든 값이 동일한 칼럼: ['대표결제방법코드']\n",
      "📌 중복 칼럼 없음\n",
      "🔹 train_청구입금정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 520열\n",
      "\n",
      "🔹 병합 진행 중: train_잔액정보.csv (파일 5 / 8)\n",
      "✅ 병합 후 데이터 크기: 2400000행, 600열\n",
      "📌 제거된 모든 값이 동일한 칼럼: ['카드론잔액_최종경과월', '최종연체개월수_R15M', 'RV잔액이월횟수_R6M', 'RV잔액이월횟수_R3M', '연체잔액_일시불_해외_B0M', '연체잔액_RV일시불_해외_B0M', '연체잔액_할부_해외_B0M', '연체잔액_CA_해외_B0M']\n",
      "📌 중복 칼럼 없음\n",
      "🔹 train_잔액정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 592열\n",
      "\n",
      "🔹 병합 진행 중: train_채널정보.csv (파일 6 / 8)\n",
      "✅ 병합 후 데이터 크기: 2400000행, 695열\n",
      "📌 제거된 모든 값이 동일한 칼럼: ['인입횟수_금융_IB_R6M', '인입불만횟수_IB_R6M', '인입불만일수_IB_R6M', '인입불만월수_IB_R6M', '인입불만후경과월_IB_R6M', '인입불만횟수_IB_B0M', '인입불만일수_IB_B0M', 'IB문의건수_한도_B0M', 'IB문의건수_결제_B0M', 'IB문의건수_할부_B0M', 'IB문의건수_정보변경_B0M', 'IB문의건수_결제일변경_B0M', 'IB문의건수_명세서_B0M', 'IB문의건수_비밀번호_B0M', 'IB문의건수_SMS_B0M', 'IB문의건수_APP_B0M', 'IB문의건수_부대서비스_B0M', 'IB문의건수_포인트_B0M', 'IB문의건수_BL_B0M', 'IB문의건수_분실도난_B0M', 'IB문의건수_CA_B0M', 'IB상담건수_VOC_B0M', 'IB상담건수_VOC민원_B0M', 'IB상담건수_VOC불만_B0M', 'IB상담건수_금감원_B0M', 'IB문의건수_명세서_R6M', 'IB문의건수_APP_R6M', 'IB상담건수_VOC_R6M', 'IB상담건수_VOC민원_R6M', 'IB상담건수_VOC불만_R6M', 'IB상담건수_금감원_R6M', '불만제기건수_B0M', '불만제기건수_R12M', '당사PAY_방문횟수_B0M', '당사PAY_방문횟수_R6M', '당사PAY_방문월수_R6M']\n",
      "📌 중복 칼럼 없음\n",
      "🔹 train_채널정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 659열\n",
      "\n",
      "🔹 병합 진행 중: train_마케팅정보.csv (파일 7 / 8)\n",
      "✅ 병합 후 데이터 크기: 2400000행, 721열\n",
      "📌 제거된 모든 값이 동일한 칼럼: ['컨택건수_CA_TM_B0M', '컨택건수_포인트소진_TM_B0M', '컨택건수_CA_EM_B0M', '컨택건수_리볼빙_EM_B0M', '컨택건수_리볼빙_청구서_B0M', '컨택건수_카드론_인터넷_B0M', '컨택건수_CA_인터넷_B0M', '컨택건수_리볼빙_인터넷_B0M', '컨택건수_카드론_당사앱_B0M', '컨택건수_CA_당사앱_B0M', '컨택건수_리볼빙_당사앱_B0M', '컨택건수_CA_EM_R6M', '컨택건수_리볼빙_EM_R6M', '컨택건수_리볼빙_청구서_R6M', '컨택건수_카드론_인터넷_R6M', '컨택건수_CA_인터넷_R6M', '컨택건수_리볼빙_인터넷_R6M', '컨택건수_카드론_당사앱_R6M', '컨택건수_CA_당사앱_R6M', '컨택건수_리볼빙_당사앱_R6M', '컨택건수_FDS_B0M', '컨택건수_FDS_R6M']\n",
      "📌 중복 칼럼 없음\n",
      "🔹 train_마케팅정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 699열\n",
      "\n",
      "🔹 병합 진행 중: train_성과정보.csv (파일 8 / 8)\n",
      "✅ 병합 후 데이터 크기: 2400000행, 746열\n",
      "📌 모든 값이 동일한 칼럼 없음\n",
      "📌 중복 칼럼 없음\n",
      "🔹 train_성과정보.csv 처리 완료. 현재 데이터 크기: 2400000행, 746열\n",
      "\n",
      "✅ 원래 데이터 크기: 2400000행, 78열\n",
      "✅ 병합 후 최종 데이터 크기: 2400000행, 746열\n",
      "\n",
      "✅ 최종 데이터 저장 완료: ./train/base_clean_train.csv\n"
     ]
    }
   ],
   "source": [
    "file_names = [\n",
    "    \"train_회원정보.csv\",\n",
    "    \"train_신용정보.csv\",\n",
    "    \"train_승인매출정보.csv\",\n",
    "    \"train_청구입금정보.csv\",\n",
    "    \"train_잔액정보.csv\",\n",
    "    \"train_채널정보.csv\",\n",
    "    \"train_마케팅정보.csv\",\n",
    "    \"train_성과정보.csv\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(f\"./train/{categories[0]}/{file_names[0]}\")\n",
    "original_shape = df.shape\n",
    "\n",
    "for idx, file in enumerate(file_names[1:], start=2):    \n",
    "    print(f\"\\n🔹 병합 진행 중: {file} (파일 {idx} / {len(file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./train/{categories[idx-1]}/{file}\")\n",
    "    df = df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")\n",
    "\n",
    "    constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    if constant_cols:\n",
    "        print(f\"📌 제거된 모든 값이 동일한 칼럼: {constant_cols}\")\n",
    "        df = df.drop(columns=constant_cols)\n",
    "    else:\n",
    "        print(\"📌 모든 값이 동일한 칼럼 없음\")\n",
    "\n",
    "    col_groups = {}\n",
    "    for col in df.columns:\n",
    "        for key in col_groups:\n",
    "            if df[col].equals(df[key]):\n",
    "                col_groups[key].append(col)\n",
    "                break\n",
    "        else:\n",
    "            col_groups[col] = [col]\n",
    "\n",
    "    duplicate_cols = [col for group in col_groups.values() for col in group[1:]]\n",
    "    if duplicate_cols:\n",
    "        print(f\"📌 제거된 중복 칼럼: {duplicate_cols}\")\n",
    "        df = df.drop(columns=duplicate_cols)\n",
    "    else:\n",
    "        print(\"📌 중복 칼럼 없음\")\n",
    "\n",
    "    if 'ID' in df.columns and df.columns.str.contains('ID').sum() > 1:\n",
    "        df = df.loc[:, ~df.columns.str.contains('ID', case=False)].join(df[['ID']])\n",
    "\n",
    "    if '기준년월' in df.columns and df.columns.str.contains('기준년월').sum() > 1:\n",
    "        df = df.loc[:, ~df.columns.str.contains('기준년월', case=False)].join(df[['기준년월']])\n",
    "\n",
    "    print(f\"🔹 {file} 처리 완료. 현재 데이터 크기: {df.shape[0]}행, {df.shape[1]}열\")\n",
    "\n",
    "new_shape = df.shape\n",
    "output_file = \"./train/base_clean_train.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 원래 데이터 크기: {original_shape[0]}행, {original_shape[1]}열\")\n",
    "print(f\"✅ 병합 후 최종 데이터 크기: {new_shape[0]}행, {new_shape[1]}열\")\n",
    "print(f\"\\n✅ 최종 데이터 저장 완료: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "594b4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 병합 진행 중: test_신용정보.csv (파일 2 / 8)\n",
      "✅ 병합 후 데이터 크기: 600000행, 117열\n",
      "\n",
      "🔹 병합 진행 중: test_승인매출정보.csv (파일 3 / 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_9280\\135895452.py:17: DtypeWarning: Columns (183) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 병합 후 데이터 크기: 600000행, 521열\n",
      "\n",
      "🔹 병합 진행 중: test_청구입금정보.csv (파일 4 / 8)\n",
      "✅ 병합 후 데이터 크기: 600000행, 565열\n",
      "\n",
      "🔹 병합 진행 중: test_잔액정보.csv (파일 5 / 8)\n",
      "✅ 병합 후 데이터 크기: 600000행, 645열\n",
      "\n",
      "🔹 병합 진행 중: test_채널정보.csv (파일 6 / 8)\n",
      "✅ 병합 후 데이터 크기: 600000행, 748열\n",
      "\n",
      "🔹 병합 진행 중: test_마케팅정보.csv (파일 7 / 8)\n",
      "✅ 병합 후 데이터 크기: 600000행, 810열\n",
      "\n",
      "🔹 병합 진행 중: test_성과정보.csv (파일 8 / 8)\n",
      "✅ 병합 후 데이터 크기: 600000행, 857열\n",
      "\n",
      "✅ 원래 test 데이터 크기: 600000행, 77열\n",
      "✅ 병합 후 최종 test 데이터 크기: 600000행, 745열\n",
      "\n",
      "✅ 최종 test 데이터 저장 완료: ./test/base_clean_test.csv\n",
      "\n",
      "⚠️ train과 test의 컬럼이 다릅니다!\n",
      "🔹 train에만 있는 컬럼 (1개): {'Segment'}\n",
      "🔹 test에만 있는 컬럼 (0개): set()\n"
     ]
    }
   ],
   "source": [
    "test_file_names = [\n",
    "    \"test_회원정보.csv\",\n",
    "    \"test_신용정보.csv\",\n",
    "    \"test_승인매출정보.csv\",\n",
    "    \"test_청구입금정보.csv\",\n",
    "    \"test_잔액정보.csv\",\n",
    "    \"test_채널정보.csv\",\n",
    "    \"test_마케팅정보.csv\",\n",
    "    \"test_성과정보.csv\"\n",
    "]\n",
    "\n",
    "test_df = pd.read_csv(f\"./test/{categories[0]}/{test_file_names[0]}\")\n",
    "test_original_shape = test_df.shape\n",
    "\n",
    "for idx, file in enumerate(test_file_names[1:], start=2):\n",
    "    print(f\"\\n🔹 병합 진행 중: {file} (파일 {idx} / {len(test_file_names)})\")\n",
    "    temp_df = pd.read_csv(f\"./test/{categories[idx-1]}/{file}\")\n",
    "    test_df = test_df.merge(temp_df, how=\"left\", on=[\"ID\", \"기준년월\"])\n",
    "    print(f\"✅ 병합 후 데이터 크기: {test_df.shape[0]}행, {test_df.shape[1]}열\")\n",
    "\n",
    "train_df = pd.read_csv(\"./train/base_clean_train.csv\", nrows=1)\n",
    "train_columns = train_df.columns\n",
    "test_columns_to_keep = [col for col in test_df.columns if col in train_columns]\n",
    "\n",
    "test_df = test_df[test_columns_to_keep]\n",
    "test_final_shape = test_df.shape\n",
    "test_output_file = \"./test/base_clean_test.csv\"\n",
    "test_df.to_csv(test_output_file, index=False)\n",
    "\n",
    "print(f\"\\n✅ 원래 test 데이터 크기: {test_original_shape[0]}행, {test_original_shape[1]}열\")\n",
    "print(f\"✅ 병합 후 최종 test 데이터 크기: {test_final_shape[0]}행, {test_final_shape[1]}열\")\n",
    "print(f\"\\n✅ 최종 test 데이터 저장 완료: {test_output_file}\")\n",
    "\n",
    "train_col_set = set(train_columns)\n",
    "test_col_set = set(test_df.columns)\n",
    "if train_col_set == test_col_set:\n",
    "    print(\"\\n✅ train과 test의 컬럼이 완전히 일치합니다!\")\n",
    "else:\n",
    "    train_only_cols = train_col_set - test_col_set\n",
    "    test_only_cols = test_col_set - train_col_set\n",
    "    print(f\"\\n⚠️ train과 test의 컬럼이 다릅니다!\")\n",
    "    print(f\"🔹 train에만 있는 컬럼 ({len(train_only_cols)}개): {train_only_cols}\")\n",
    "    print(f\"🔹 test에만 있는 컬럼 ({len(test_only_cols)}개): {test_only_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd64399",
   "metadata": {},
   "source": [
    "# Modeling - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298c2432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.8.0+cu126\n",
      "torch.version.cuda: 12.6\n",
      "cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torch.version.cuda:\", torch.version.cuda)   # 12.1 또는 11.8이어야 함 (None이면 CPU 빌드)\n",
    "print(\"cuda available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3469fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10828\\935452068.py:1: DtypeWarning: Columns (281,355) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('./train/base_clean_train.csv')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_10828\\935452068.py:2: DtypeWarning: Columns (280) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('./test/base_clean_test.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Fold 1 training...\n",
      "0:\tlearn: 0.8425386\ttotal: 471ms\tremaining: 11m 45s\n",
      "100:\tlearn: 0.9047615\ttotal: 20.5s\tremaining: 4m 43s\n",
      "200:\tlearn: 0.9178781\ttotal: 39.8s\tremaining: 4m 17s\n",
      "300:\tlearn: 0.9271276\ttotal: 59s\tremaining: 3m 54s\n",
      "400:\tlearn: 0.9338885\ttotal: 1m 18s\tremaining: 3m 34s\n",
      "500:\tlearn: 0.9397080\ttotal: 1m 37s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.9447890\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.9493018\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9527193\ttotal: 2m 33s\tremaining: 2m 14s\n",
      "900:\tlearn: 0.9560647\ttotal: 2m 52s\tremaining: 1m 54s\n",
      "1000:\tlearn: 0.9591432\ttotal: 3m 11s\tremaining: 1m 35s\n",
      "1100:\tlearn: 0.9619612\ttotal: 3m 30s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9645073\ttotal: 3m 49s\tremaining: 57.2s\n",
      "1300:\tlearn: 0.9668168\ttotal: 4m 9s\tremaining: 38.1s\n",
      "1400:\tlearn: 0.9690598\ttotal: 4m 28s\tremaining: 19s\n",
      "1499:\tlearn: 0.9709365\ttotal: 4m 47s\tremaining: 0us\n",
      "🚀 Fold 2 training...\n",
      "0:\tlearn: 0.8425332\ttotal: 526ms\tremaining: 13m 8s\n",
      "100:\tlearn: 0.9043988\ttotal: 20.8s\tremaining: 4m 47s\n",
      "200:\tlearn: 0.9180394\ttotal: 40.3s\tremaining: 4m 20s\n",
      "300:\tlearn: 0.9270312\ttotal: 59.9s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.9340196\ttotal: 1m 19s\tremaining: 3m 37s\n",
      "500:\tlearn: 0.9399271\ttotal: 1m 38s\tremaining: 3m 16s\n",
      "600:\tlearn: 0.9449960\ttotal: 1m 57s\tremaining: 2m 55s\n",
      "700:\tlearn: 0.9493859\ttotal: 2m 17s\tremaining: 2m 36s\n",
      "800:\tlearn: 0.9527436\ttotal: 2m 34s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9562889\ttotal: 2m 53s\tremaining: 1m 55s\n",
      "1000:\tlearn: 0.9591709\ttotal: 3m 12s\tremaining: 1m 35s\n",
      "1100:\tlearn: 0.9617778\ttotal: 3m 30s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9642611\ttotal: 3m 49s\tremaining: 57.1s\n",
      "1300:\tlearn: 0.9664635\ttotal: 4m 7s\tremaining: 37.9s\n",
      "1400:\tlearn: 0.9687289\ttotal: 4m 26s\tremaining: 18.8s\n",
      "1499:\tlearn: 0.9707342\ttotal: 4m 45s\tremaining: 0us\n",
      "🚀 Fold 3 training...\n",
      "0:\tlearn: 0.8426860\ttotal: 493ms\tremaining: 12m 18s\n",
      "100:\tlearn: 0.9045701\ttotal: 20.6s\tremaining: 4m 45s\n",
      "200:\tlearn: 0.9179532\ttotal: 39.1s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9272412\ttotal: 58.8s\tremaining: 3m 54s\n",
      "400:\tlearn: 0.9342107\ttotal: 1m 17s\tremaining: 3m 33s\n",
      "500:\tlearn: 0.9400835\ttotal: 1m 37s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.9453626\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.9499432\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9539701\ttotal: 2m 35s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9572558\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "1000:\tlearn: 0.9601092\ttotal: 3m 14s\tremaining: 1m 36s\n",
      "1100:\tlearn: 0.9630344\ttotal: 3m 34s\tremaining: 1m 17s\n",
      "1200:\tlearn: 0.9656725\ttotal: 3m 53s\tremaining: 58.2s\n",
      "1300:\tlearn: 0.9679385\ttotal: 4m 13s\tremaining: 38.8s\n",
      "1400:\tlearn: 0.9701198\ttotal: 4m 33s\tremaining: 19.3s\n",
      "1499:\tlearn: 0.9721755\ttotal: 4m 52s\tremaining: 0us\n",
      "🚀 Fold 4 training...\n",
      "0:\tlearn: 0.8426603\ttotal: 473ms\tremaining: 11m 49s\n",
      "100:\tlearn: 0.9041164\ttotal: 20.6s\tremaining: 4m 44s\n",
      "200:\tlearn: 0.9176078\ttotal: 40s\tremaining: 4m 18s\n",
      "300:\tlearn: 0.9266643\ttotal: 59.1s\tremaining: 3m 55s\n",
      "400:\tlearn: 0.9336928\ttotal: 1m 18s\tremaining: 3m 35s\n",
      "500:\tlearn: 0.9395504\ttotal: 1m 38s\tremaining: 3m 15s\n",
      "600:\tlearn: 0.9444340\ttotal: 1m 57s\tremaining: 2m 55s\n",
      "700:\tlearn: 0.9487646\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9526735\ttotal: 2m 35s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9560742\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "1000:\tlearn: 0.9586486\ttotal: 3m 12s\tremaining: 1m 36s\n",
      "1100:\tlearn: 0.9614551\ttotal: 3m 31s\tremaining: 1m 16s\n",
      "1200:\tlearn: 0.9640892\ttotal: 3m 50s\tremaining: 57.4s\n",
      "1300:\tlearn: 0.9664665\ttotal: 4m 9s\tremaining: 38.1s\n",
      "1400:\tlearn: 0.9686899\ttotal: 4m 28s\tremaining: 18.9s\n",
      "1499:\tlearn: 0.9707324\ttotal: 4m 46s\tremaining: 0us\n",
      "🚀 Fold 5 training...\n",
      "0:\tlearn: 0.8423167\ttotal: 498ms\tremaining: 12m 26s\n",
      "100:\tlearn: 0.9044024\ttotal: 20.5s\tremaining: 4m 43s\n",
      "200:\tlearn: 0.9176462\ttotal: 40.2s\tremaining: 4m 19s\n",
      "300:\tlearn: 0.9268466\ttotal: 59.3s\tremaining: 3m 56s\n",
      "400:\tlearn: 0.9340366\ttotal: 1m 18s\tremaining: 3m 35s\n",
      "500:\tlearn: 0.9399004\ttotal: 1m 37s\tremaining: 3m 14s\n",
      "600:\tlearn: 0.9449794\ttotal: 1m 56s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.9494178\ttotal: 2m 16s\tremaining: 2m 35s\n",
      "800:\tlearn: 0.9528307\ttotal: 2m 35s\tremaining: 2m 15s\n",
      "900:\tlearn: 0.9563497\ttotal: 2m 54s\tremaining: 1m 56s\n",
      "1000:\tlearn: 0.9595126\ttotal: 3m 13s\tremaining: 1m 36s\n",
      "1100:\tlearn: 0.9623773\ttotal: 3m 32s\tremaining: 1m 17s\n",
      "1200:\tlearn: 0.9649621\ttotal: 3m 52s\tremaining: 57.9s\n",
      "1300:\tlearn: 0.9673960\ttotal: 4m 11s\tremaining: 38.5s\n",
      "1400:\tlearn: 0.9695366\ttotal: 4m 31s\tremaining: 19.2s\n",
      "1499:\tlearn: 0.9716132\ttotal: 4m 50s\tremaining: 0us\n",
      "🚀 Fold 6 training...\n",
      "0:\tlearn: 0.8424855\ttotal: 397ms\tremaining: 9m 54s\n",
      "100:\tlearn: 0.9042097\ttotal: 20s\tremaining: 4m 37s\n",
      "200:\tlearn: 0.9182806\ttotal: 39s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9270824\ttotal: 58s\tremaining: 3m 50s\n",
      "400:\tlearn: 0.9341902\ttotal: 1m 16s\tremaining: 3m 30s\n",
      "500:\tlearn: 0.9398708\ttotal: 1m 35s\tremaining: 3m 10s\n",
      "600:\tlearn: 0.9450650\ttotal: 1m 54s\tremaining: 2m 51s\n",
      "700:\tlearn: 0.9494845\ttotal: 2m 13s\tremaining: 2m 32s\n",
      "800:\tlearn: 0.9536105\ttotal: 2m 32s\tremaining: 2m 13s\n",
      "900:\tlearn: 0.9569970\ttotal: 2m 51s\tremaining: 1m 53s\n",
      "1000:\tlearn: 0.9599590\ttotal: 3m 10s\tremaining: 1m 34s\n",
      "1100:\tlearn: 0.9627202\ttotal: 3m 28s\tremaining: 1m 15s\n",
      "1200:\tlearn: 0.9653036\ttotal: 3m 47s\tremaining: 56.7s\n",
      "1300:\tlearn: 0.9676975\ttotal: 4m 6s\tremaining: 37.8s\n",
      "1400:\tlearn: 0.9695956\ttotal: 4m 25s\tremaining: 18.7s\n",
      "1499:\tlearn: 0.9714685\ttotal: 4m 44s\tremaining: 0us\n",
      "🚀 Fold 7 training...\n",
      "0:\tlearn: 0.8424702\ttotal: 479ms\tremaining: 11m 58s\n",
      "100:\tlearn: 0.9045393\ttotal: 20.4s\tremaining: 4m 42s\n",
      "200:\tlearn: 0.9180739\ttotal: 39.1s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9269841\ttotal: 57.8s\tremaining: 3m 50s\n",
      "400:\tlearn: 0.9339369\ttotal: 1m 16s\tremaining: 3m 28s\n",
      "500:\tlearn: 0.9398656\ttotal: 1m 34s\tremaining: 3m 9s\n",
      "600:\tlearn: 0.9448688\ttotal: 1m 53s\tremaining: 2m 50s\n",
      "700:\tlearn: 0.9493509\ttotal: 2m 12s\tremaining: 2m 31s\n",
      "800:\tlearn: 0.9528888\ttotal: 2m 31s\tremaining: 2m 11s\n",
      "900:\tlearn: 0.9548967\ttotal: 2m 46s\tremaining: 1m 51s\n",
      "1000:\tlearn: 0.9581213\ttotal: 3m 5s\tremaining: 1m 32s\n",
      "1100:\tlearn: 0.9607655\ttotal: 3m 24s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9634992\ttotal: 3m 43s\tremaining: 55.6s\n",
      "1300:\tlearn: 0.9660996\ttotal: 4m 2s\tremaining: 37.1s\n",
      "1400:\tlearn: 0.9684261\ttotal: 4m 22s\tremaining: 18.5s\n",
      "1499:\tlearn: 0.9705265\ttotal: 4m 41s\tremaining: 0us\n",
      "🚀 Fold 8 training...\n",
      "0:\tlearn: 0.8424734\ttotal: 461ms\tremaining: 11m 30s\n",
      "100:\tlearn: 0.9043580\ttotal: 20.1s\tremaining: 4m 38s\n",
      "200:\tlearn: 0.9178630\ttotal: 38.6s\tremaining: 4m 9s\n",
      "300:\tlearn: 0.9270163\ttotal: 57.6s\tremaining: 3m 49s\n",
      "400:\tlearn: 0.9342272\ttotal: 1m 16s\tremaining: 3m 29s\n",
      "500:\tlearn: 0.9400690\ttotal: 1m 35s\tremaining: 3m 10s\n",
      "600:\tlearn: 0.9451051\ttotal: 1m 54s\tremaining: 2m 50s\n",
      "700:\tlearn: 0.9495942\ttotal: 2m 13s\tremaining: 2m 31s\n",
      "800:\tlearn: 0.9533284\ttotal: 2m 32s\tremaining: 2m 12s\n",
      "900:\tlearn: 0.9560002\ttotal: 2m 49s\tremaining: 1m 52s\n",
      "1000:\tlearn: 0.9593109\ttotal: 3m 8s\tremaining: 1m 33s\n",
      "1100:\tlearn: 0.9618303\ttotal: 3m 26s\tremaining: 1m 14s\n",
      "1200:\tlearn: 0.9642777\ttotal: 3m 44s\tremaining: 56s\n",
      "1300:\tlearn: 0.9663189\ttotal: 4m 3s\tremaining: 37.2s\n",
      "1400:\tlearn: 0.9684567\ttotal: 4m 21s\tremaining: 18.5s\n",
      "1499:\tlearn: 0.9703993\ttotal: 4m 40s\tremaining: 0us\n",
      "🚀 Fold 9 training...\n",
      "0:\tlearn: 0.8425640\ttotal: 548ms\tremaining: 13m 41s\n",
      "100:\tlearn: 0.9044450\ttotal: 20.9s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.9179953\ttotal: 40.5s\tremaining: 4m 22s\n",
      "300:\tlearn: 0.9269375\ttotal: 60s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.9340943\ttotal: 1m 19s\tremaining: 3m 38s\n",
      "500:\tlearn: 0.9400001\ttotal: 1m 39s\tremaining: 3m 17s\n",
      "600:\tlearn: 0.9448799\ttotal: 1m 58s\tremaining: 2m 57s\n",
      "700:\tlearn: 0.9493197\ttotal: 2m 18s\tremaining: 2m 37s\n",
      "800:\tlearn: 0.9532658\ttotal: 2m 38s\tremaining: 2m 17s\n",
      "900:\tlearn: 0.9567788\ttotal: 2m 57s\tremaining: 1m 58s\n",
      "1000:\tlearn: 0.9598023\ttotal: 3m 17s\tremaining: 1m 38s\n",
      "1100:\tlearn: 0.9627275\ttotal: 3m 36s\tremaining: 1m 18s\n",
      "1200:\tlearn: 0.9652777\ttotal: 3m 56s\tremaining: 58.8s\n",
      "1300:\tlearn: 0.9676854\ttotal: 4m 16s\tremaining: 39.2s\n",
      "1400:\tlearn: 0.9698594\ttotal: 4m 36s\tremaining: 19.5s\n",
      "1499:\tlearn: 0.9718434\ttotal: 4m 55s\tremaining: 0us\n",
      "🚀 Fold 10 training...\n",
      "0:\tlearn: 0.8425672\ttotal: 529ms\tremaining: 13m 12s\n",
      "100:\tlearn: 0.9045408\ttotal: 20.8s\tremaining: 4m 47s\n",
      "200:\tlearn: 0.9180421\ttotal: 40.3s\tremaining: 4m 20s\n",
      "300:\tlearn: 0.9270589\ttotal: 60s\tremaining: 3m 58s\n",
      "400:\tlearn: 0.9344468\ttotal: 1m 19s\tremaining: 3m 37s\n",
      "500:\tlearn: 0.9401405\ttotal: 1m 38s\tremaining: 3m 16s\n",
      "600:\tlearn: 0.9452368\ttotal: 1m 58s\tremaining: 2m 56s\n",
      "700:\tlearn: 0.9496597\ttotal: 2m 17s\tremaining: 2m 36s\n",
      "800:\tlearn: 0.9536272\ttotal: 2m 37s\tremaining: 2m 17s\n",
      "900:\tlearn: 0.9570600\ttotal: 2m 56s\tremaining: 1m 57s\n",
      "1000:\tlearn: 0.9602073\ttotal: 3m 16s\tremaining: 1m 37s\n",
      "1100:\tlearn: 0.9630984\ttotal: 3m 36s\tremaining: 1m 18s\n",
      "1200:\tlearn: 0.9655991\ttotal: 3m 55s\tremaining: 58.6s\n",
      "1300:\tlearn: 0.9677257\ttotal: 4m 14s\tremaining: 39s\n",
      "1400:\tlearn: 0.9696679\ttotal: 4m 34s\tremaining: 19.4s\n",
      "1499:\tlearn: 0.9715540\ttotal: 4m 53s\tremaining: 0us\n",
      "✅ CatBoost + 10-Fold CV 예측 완료 및 저장 🎯\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/base_clean_train.csv')\n",
    "test = pd.read_csv('./test/base_clean_test.csv')\n",
    "\n",
    "ab_ids = train[train['Segment'].isin(['A', 'B'])]['ID'].unique()\n",
    "train = train[~train['ID'].isin(ab_ids)].copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "best_params = {\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"learning_rate\": 0.2997682904093563,\n",
    "    \"l2_leaf_reg\": 9.214022161348987,\n",
    "    \"random_strength\": 7.342192789415524,\n",
    "    \"bagging_temperature\": 0.11417356499443036,\n",
    "    \"border_count\": 251,\n",
    "    \"iterations\": 1500,\n",
    "    \"loss_function\": \"MultiClass\",\n",
    "    \"eval_metric\": \"TotalF1\",\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"verbose\": 100,\n",
    "    \"random_seed\": 42,\n",
    "    \"depth\": 8,\n",
    "    \"class_weights\": [2, 1, 1]\n",
    "}\n",
    "\n",
    "n_classes = len(np.unique(y))\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"🚀 Fold {fold+1} training...\")\n",
    "    X_train_fold, y_train_fold = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    X_valid_fold, y_valid_fold = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "    model = CatBoostClassifier(**best_params)\n",
    "    model.fit(X_train_fold, y_train_fold, cat_features=cat_features)\n",
    "    fold_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += fold_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=range(n_classes))\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs.drop(columns='ID').values.argmax(axis=1)\n",
    "segment_mapping = {0: 'C', 1: 'D', 2: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "submission = pd.DataFrame({'ID': mean_probs['ID'], 'Segment': mean_probs['Segment']})\n",
    "submission.to_csv('./test/base_catboost_kfold.csv', index=False)\n",
    "print(\"✅ CatBoost + 10-Fold CV 예측 완료 및 저장 🎯\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50fdd9",
   "metadata": {},
   "source": [
    "# Data Preprocessing - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30ae1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2696\\216419294.py:1: DtypeWarning: Columns (281,355) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train = pd.read_csv('./train/base_clean_train.csv')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_2696\\216419294.py:2: DtypeWarning: Columns (280) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test = pd.read_csv('./test/base_clean_test.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 고정된 칼럼 83개 제거할 예정입니다.\n",
      "🚀 최종 train 데이터 shape: (249594, 663)\n",
      "🚀 최종 test 데이터 shape: (62586, 662)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/base_clean_train.csv')\n",
    "test = pd.read_csv('./test/base_clean_test.csv')\n",
    "\n",
    "train_A = train[train['Segment'] == 'A']\n",
    "cols_to_check = [col for col in train.columns if col not in ['ID', 'Segment']]\n",
    "\n",
    "def is_fixed_column(df, col):\n",
    "    return df[col].nunique() == 1\n",
    "\n",
    "fixed_columns_A = {col: train_A[col].iloc[0] for col in cols_to_check if is_fixed_column(train_A, col)}\n",
    "fixed_cols = list(fixed_columns_A.keys())\n",
    "print(f\"📦 고정된 칼럼 {len(fixed_cols)}개 제거할 예정입니다.\")\n",
    "\n",
    "matching_ids_train = train.copy()\n",
    "for col, value in fixed_columns_A.items():\n",
    "    matching_ids_train = matching_ids_train[matching_ids_train[col] == value]\n",
    "matching_ids_train_list = matching_ids_train.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "matching_ids_test = test.copy()\n",
    "for col, value in fixed_columns_A.items():\n",
    "    matching_ids_test = matching_ids_test[matching_ids_test[col] == value]\n",
    "matching_ids_test_list = matching_ids_test.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "train_filtered = train[train['ID'].isin(matching_ids_train_list)].drop(columns=fixed_cols)\n",
    "test_filtered = test[test['ID'].isin(matching_ids_test_list)].drop(columns=fixed_cols)\n",
    "\n",
    "print(f\"🚀 최종 train 데이터 shape: {train_filtered.shape}\")\n",
    "print(f\"🚀 최종 test 데이터 shape: {test_filtered.shape}\")\n",
    "train_filtered.to_csv('./train/train_vips_A.csv', index=False)\n",
    "test_filtered.to_csv('./test/test_vips_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd833566",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train/base_clean_train.csv')\n",
    "test = pd.read_csv('./test/base_clean_test.csv')\n",
    "\n",
    "train_B = train[train['Segment'] == 'B']\n",
    "cols_to_check = [col for col in train.columns if col not in ['ID', 'Segment']]\n",
    "\n",
    "fixed_columns_B = {col: train_B[col].iloc[0] for col in cols_to_check if is_fixed_column(train_B, col)}\n",
    "fixed_cols = list(fixed_columns_B.keys())\n",
    "print(f\"📦 고정된 칼럼 {len(fixed_cols)}개 제거할 예정입니다.\")\n",
    "\n",
    "matching_ids_train = train.copy()\n",
    "for col, value in fixed_columns_B.items():\n",
    "    matching_ids_train = matching_ids_train[matching_ids_train[col] == value]\n",
    "matching_ids_train_list = matching_ids_train.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "matching_ids_test = test.copy()\n",
    "for col, value in fixed_columns_B.items():\n",
    "    matching_ids_test = matching_ids_test[matching_ids_test[col] == value]\n",
    "matching_ids_test_list = matching_ids_test.groupby('ID').filter(lambda x: len(x) == 6)['ID'].unique()\n",
    "\n",
    "train_filtered = train[train['ID'].isin(matching_ids_train_list)].drop(columns=fixed_cols)\n",
    "test_filtered = test[test['ID'].isin(matching_ids_test_list)].drop(columns=fixed_cols)\n",
    "\n",
    "print(f\"🚀 최종 train 데이터 shape: {train_filtered.shape}\")\n",
    "print(f\"🚀 최종 test 데이터 shape: {test_filtered.shape}\")\n",
    "train_filtered.to_csv('./train/train_vips_B.csv', index=False)\n",
    "test_filtered.to_csv('./test/test_vips_B.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ed0bc",
   "metadata": {},
   "source": [
    "# Modeling - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89890ce2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m./train/train_vips_A.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m./test/test_vips_A.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m label_encoder = LabelEncoder()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/train_vips_A.csv')\n",
    "test = pd.read_csv('./test/test_vips_A.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "params = {\n",
    "    'iterations': 2000,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 6,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'task_type': 'GPU',\n",
    "    'class_weights': [20, 50, 2, 1, 1],\n",
    "}\n",
    "\n",
    "n_classes = 5\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n🚀 단일 Model Run 시작\")\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"📂 Fold {fold + 1}\")\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=(X_valid_fold, y_valid_fold),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += test_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=[0, 1, 2, 3, 4])\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs[[0, 1, 2, 3, 4]].idxmax(axis=1)\n",
    "segment_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "a_ids = mean_probs.loc[mean_probs['Segment'] == 'A', 'ID'].tolist()\n",
    "print(f\"\\n✅ A로 분류된 ID 수 = {len(a_ids)}개\")\n",
    "print(f\"🔎 A ID: {a_ids[:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc55e3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33m./train/train_vips_B.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m test = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33m./test/test_vips_B.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m label_encoder = LabelEncoder()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./train/train_vips_B.csv')\n",
    "test = pd.read_csv('./test/test_vips_B.csv')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train['Segment'] = label_encoder.fit_transform(train['Segment'])\n",
    "\n",
    "X = train.drop(columns=['Segment', 'ID'])\n",
    "y = train['Segment']\n",
    "X_test = test.drop(columns=['ID'])\n",
    "\n",
    "cat_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype(str)\n",
    "    X_test[col] = X_test[col].astype(str)\n",
    "\n",
    "params = {\n",
    "    'iterations': 1000,\n",
    "    'learning_rate': 0.03,\n",
    "    'depth': 8,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'eval_metric': 'MultiClass',\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'task_type': 'GPU',\n",
    "    'class_weights': [10, 10, 1, 1, 1],\n",
    "}\n",
    "\n",
    "n_classes = 5\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"\\n🚀 단일 Model Run 시작\")\n",
    "all_test_probs = np.zeros((X_test.shape[0], n_classes))\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X, y)):\n",
    "    print(f\"📂 Fold {fold + 1}\")\n",
    "    X_train_fold, X_valid_fold = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train_fold, y_valid_fold = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        eval_set=(X_valid_fold, y_valid_fold),\n",
    "        cat_features=cat_features,\n",
    "        early_stopping_rounds=100,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    test_probs = model.predict_proba(X_test)\n",
    "    all_test_probs += test_probs\n",
    "\n",
    "avg_test_probs = all_test_probs / kf.get_n_splits()\n",
    "prob_df = pd.DataFrame(avg_test_probs, columns=[0, 1, 2, 3, 4])\n",
    "prob_df['ID'] = test['ID'].values\n",
    "\n",
    "mean_probs = prob_df.groupby('ID').mean().reset_index()\n",
    "mean_probs['Segment'] = mean_probs[[0, 1, 2, 3, 4]].idxmax(axis=1)\n",
    "segment_mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E'}\n",
    "mean_probs['Segment'] = mean_probs['Segment'].map(segment_mapping)\n",
    "\n",
    "b_ids = mean_probs.loc[mean_probs['Segment'] == 'B', 'ID'].tolist()\n",
    "print(f\"\\n✅ B로 분류된 ID 수 = {len(b_ids)}개\")\n",
    "print(f\"🔎 B ID: {b_ids[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5fae76",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv('./test/base_catboost_kfold.csv')\n",
    "base_df.loc[base_df['ID'].isin(a_ids), 'Segment'] = 'A'\n",
    "base_df.loc[base_df['ID'].isin(b_ids), 'Segment'] = 'B'\n",
    "base_df.to_csv('./test/final_catboost.csv', index=False)\n",
    "\n",
    "print(f\"✅ Segment가 'A'로 수정된 {len(a_ids)}개 ID 반영 완료\")\n",
    "print(f\"✅ Segment가 'B'로 수정된 {len(b_ids)}개 ID 반영 완료\")\n",
    "print(\"🎯 최종 결과 저장 완료: final_catboost.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
